{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55979389-d4c3-4a4c-aaf7-6229dc7da02a",
   "metadata": {},
   "source": [
    "## The g2o solvers available  \n",
    "\n",
    "Here's a list of some of the solvers available in `g2o` and a brief explanation of each:\n",
    "\n",
    "1. **Dense Solvers**:\n",
    "    - **Cholesky (CSparse, Cholmod)**: These solvers are used for dense matrices and are based on Cholesky factorization. They are efficient for small to medium-sized problems where the Hessian matrix is dense.\n",
    "\n",
    "2. **Sparse Solvers**:\n",
    "    - **PCG (Preconditioned Conjugate Gradient)**: Suitable for large sparse systems. PCG is an iterative solver that can handle very large problems efficiently when combined with a good preconditioner.\n",
    "    - **SLAM-specific Solvers (Block solvers)**: These are designed to exploit the sparsity pattern of SLAM problems, where the Hessian matrix has a block structure. Examples include block Cholesky and block Jacobi methods.\n",
    "    - **Levenberg-Marquardt**: An algorithm used to solve nonlinear least squares problems. It's particularly useful for problems where the error function is well approximated by a quadratic form near the minimum.\n",
    "\n",
    "3. **Schur-based Solvers**:\n",
    "    - **Schur Complements**: These solvers take advantage of the special structure of the Hessian matrix in certain problems (like SLAM) to reduce the size of the system before solving it. This can lead to significant performance improvements.\n",
    "\n",
    "4. **Iterative Solvers**:\n",
    "    - **Gauss-Seidel and Jacobi**: These are iterative methods suitable for large sparse systems. They can be very efficient for certain types of problems but may require a good initial guess to converge quickly.\n",
    "\n",
    "5. **Direct Solvers**:\n",
    "    - **Sparse Cholesky (CSparse, Cholmod)**: Direct methods that are efficient for solving systems of linear equations where the coefficient matrix is sparse and symmetric positive definite.\n",
    "\n",
    "6. **Preconditioners**:\n",
    "    - **Jacobi, Incomplete Cholesky, etc.**: These are not solvers per se but are crucial for improving the convergence rate of iterative solvers. They work by transforming the system into a form that is easier to solve.\n",
    "\n",
    "7. **Custom and Hybrid Solvers**:\n",
    "    - **Custom Implementations**: Users can implement their solvers or modify existing ones to better suit their specific problems. `g2o` provides a flexible framework that can be extended with custom optimization techniques.\n",
    "\n",
    "\n",
    "# g2o optimization algorithms\n",
    "In `g2o`, optimization algorithms are crucial for solving the graph-based nonlinear optimization problems. The framework provides several algorithms, each suited to different types of problems and optimization requirements. Here's a list of some of the optimization algorithms available in `g2o` along with a brief explanation:\n",
    "\n",
    "1. **Gauss-Newton Algorithm**: This algorithm is used for minimizing nonlinear least squares problems. It approximates the nonlinear model with a linear one in each iteration, solving the linearized problem to update the parameters. It's efficient for problems where the initial guess is relatively close to the optimal solution.\n",
    "\n",
    "2. **Levenberg-Marquardt Algorithm**: An improvement over the Gauss-Newton algorithm, it adds a damping factor to improve convergence when far from the minimum. This makes it more robust than Gauss-Newton, especially in the presence of local minima or when the initial guess is not close to the solution.\n",
    "\n",
    "3. **Powell's Dog Leg Algorithm**: This algorithm is a trust-region method that combines the Gauss-Newton and gradient descent directions. It's useful for problems where the error surface is poorly conditioned, and it adjusts the step size based on the trust region's size.\n",
    "\n",
    "4. **Conjugate Gradient Algorithm**: An iterative method for solving linear systems that arise in the optimization of large sparse problems. It's particularly useful when the Hessian matrix is too large to factorize directly.\n",
    "\n",
    "5. **Steepest Descent Algorithm**: The simplest gradient-based optimization algorithm. It updates parameters in the direction of the steepest descent (negative gradient) to minimize the error. While straightforward and easy to implement, it can be slow to converge, especially for ill-conditioned problems.\n",
    "\n",
    "6. **Robust Optimization Algorithms**: `g2o` includes support for robust cost functions to mitigate the influence of outliers. These are not algorithms per se but are modifications to the cost function used with other algorithms to improve robustness against outliers.\n",
    "\n",
    "Each of these algorithms can be chosen based on the specific characteristics of the optimization problem, such as the size of the problem, the nature of the cost function, the presence of noise and outliers, and the computational resources available. The choice of algorithm can significantly affect both the speed and the quality of the optimization results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023562b2-9324-4c7b-9033-3be9f9fbb280",
   "metadata": {},
   "source": [
    "```\n",
    "import pyg2o\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = pyg2o.SparseOptimizer()\n",
    "\n",
    "# Select a solver. The exact way to do this can vary.\n",
    "solver = pyg2o.BlockSolverX(pyg2o.LinearSolverCSparseX())\n",
    "optimization_algorithm = pyg2o.OptimizationAlgorithmLevenberg(solver)\n",
    "optimizer.set_algorithm(optimization_algorithm)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd2e45-432c-410e-8f29-70a0a8940ecf",
   "metadata": {},
   "source": [
    " Here are explanations for the provided solver and additional types you might consider:\n",
    "\n",
    "1. **BlockSolverX with LinearSolverEigenX**:\n",
    "   - This setup is generic, where `X` implies flexibility or adaptability to different types of problems. It's suitable for problems with variable dimensions and is configured to use Eigen for solving the underlying linear systems.\n",
    "\n",
    "2. **BlockSolverSE3 with LinearSolverEigenSE3**:\n",
    "   - This is specialized for problems involving 3D poses, where SE3 represents the group of rigid body transformations in 3D space. It's particularly relevant in robotics and computer vision, especially for SLAM and 3D reconstruction problems. The `SE3` component indicates that the solver is optimized for handling the SE3 manifold specifically.\n",
    "\n",
    "For creating other types of solvers, you might consider the following patterns, assuming they are supported by the Python wrapper you're using:\n",
    "\n",
    "- **BlockSolverPose2D with LinearSolverEigenPose2D**:\n",
    "  - For 2D pose estimation problems, where you're dealing with planar movements. This can be useful in 2D SLAM or other robotics applications where the environment is essentially 2D.\n",
    "\n",
    "- **BlockSolverXYZ with LinearSolverEigenXYZ**:\n",
    "  - For problems that involve optimizing the 3D positions of points, such as in structure from motion (SfM) or other 3D reconstruction tasks. This would be focused on the optimization of point cloud coordinates.\n",
    "\n",
    "Each of these setups is tailored to a specific type of optimization problem, leveraging the strengths of the Eigen library for efficient matrix operations. The key is to match the solver to the structure of your problem:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9299fcd4-6a69-46b4-a929-03acf3b147cf",
   "metadata": {},
   "source": [
    "##  Building a pose graph with g2o from consecutive images with OpenCV\n",
    "\n",
    "\n",
    "Building a pose graph with `g2o` from consecutive images, using keypoints, matches, and the relative pose (rotation `R` and translation `t`) computed with OpenCV involves several steps. I'll outline a general approach to create and optimize a pose graph using these components. Since your question implies you're working in Python, I'll keep the explanation suited to a Python context, assuming you're using a Python wrapper for `g2o`.\n",
    "\n",
    "### Step 1: Preprocessing with OpenCV\n",
    "\n",
    "You've already completed this step by extracting keypoints from images, matching them using `FlannBasedMatcher`, and then using `cv2.recoverPose` to compute the relative rotation (`R`) and translation (`t`) between pairs of images.\n",
    "\n",
    "### Step 2: Initialize the Pose Graph in g2o\n",
    "\n",
    "1. **Import g2o Python Wrapper**: Ensure you have a Python wrapper for `g2o` installed and accessible in your environment.\n",
    "\n",
    "2. **Create an Optimizer**: This will manage the graph and perform the optimization.\n",
    "\n",
    "   ```python\n",
    "   import g2o\n",
    "\n",
    "   optimizer = g2o.SparseOptimizer()\n",
    "   solver = g2o.BlockSolverSE3(g2o.LinearSolverEigenSE3())\n",
    "   algorithm = g2o.OptimizationAlgorithmLevenberg(solver)\n",
    "   optimizer.set_algorithm(algorithm)\n",
    "   ```\n",
    "\n",
    "### Step 3: Add Nodes to the Graph\n",
    "\n",
    "Each node in the pose graph represents a camera pose (or frame). The first pose can be set as the origin (identity matrix for rotation and zero vector for translation) to anchor the graph.\n",
    "\n",
    "```python\n",
    "for i, pose in enumerate(poses):\n",
    "    # Assuming `pose` is a 4x4 transformation matrix [R|t]\n",
    "    # or you construct it from R and t\n",
    "    se3_quat = g2o.SE3Quat(pose[:3, :3], pose[:3, 3])\n",
    "    vertex = g2o.VertexSE3Expmap()\n",
    "    vertex.set_id(i)\n",
    "    vertex.set_estimate(se3_quat)\n",
    "    if i == 0:\n",
    "        # Fix the first node to anchor the graph\n",
    "        vertex.set_fixed(True)\n",
    "    optimizer.add_vertex(vertex)\n",
    "```\n",
    "\n",
    "### Step 4: Add Edges to the Graph\n",
    "\n",
    "Edges represent the relative transformations (computed by `cv2.recoverPose`) between pairs of images. Each edge connects two nodes and carries the relative pose information.\n",
    "\n",
    "```python\n",
    "for (idx1, idx2), (R, t) in relative_poses.items():\n",
    "    # Create an edge between vertex `idx1` and `idx2`\n",
    "    edge = g2o.EdgeSE3Expmap()\n",
    "\n",
    "    # `relative_pose` is the transformation from `idx1` to `idx2`\n",
    "    se3_quat = g2o.SE3Quat(R, t)\n",
    "    \n",
    "    edge.set_vertex(0, optimizer.vertex(idx1))\n",
    "    edge.set_vertex(1, optimizer.vertex(idx2))\n",
    "    edge.set_measurement(se3_quat)\n",
    "    \n",
    "    # Information matrix: the inverse of the covariance matrix\n",
    "    # Adjust these values based on the confidence in the measurement\n",
    "    information = np.eye(6)  # Simplified example; adjust as needed\n",
    "    edge.set_information(information)\n",
    "\n",
    "    optimizer.add_edge(edge)\n",
    "```\n",
    "\n",
    "### Step 5: Optimize the Pose Graph\n",
    "\n",
    "After constructing the graph, you can optimize it to refine the poses based on the relative measurements.\n",
    "\n",
    "```python\n",
    "optimizer.initialize_optimization()\n",
    "optimizer.optimize(num_iterations)  # Specify the number of iterations\n",
    "```\n",
    "\n",
    "### Step 6: Extract Optimized Poses\n",
    "\n",
    "After optimization, you can extract the optimized poses (positions and orientations) of each camera frame from the graph.\n",
    "\n",
    "```python\n",
    "optimized_poses = []\n",
    "for i in range(optimizer.vertices().size()):\n",
    "    vertex = optimizer.vertex(i)\n",
    "    pose = vertex.estimate()  # This is a g2o.SE3Quat object\n",
    "    optimized_poses.append(pose.to_matrix())  # Convert to a 4x4 transformation matrix\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ce450-a668-4b07-ad20-2362a9dec7ad",
   "metadata": {},
   "source": [
    " ## loop detection with Bow\n",
    "\n",
    "Integrating a Bag of Words (BoW) model for loop detection into your SLAM system involves several steps. Once a loop is detected, you can update the pose graph with the new information and re-optimize it. Here's a high-level overview of how to approach this:\n",
    "\n",
    "### Step 1: Implement or Integrate a BoW Model\n",
    "\n",
    "1. **Feature Extraction**: Continue extracting features from each image as you've been doing. These features are used to populate the BoW model.\n",
    "\n",
    "2. **BoW Model Creation**: Use an existing BoW library or framework suited for visual applications, such as DBoW2 or OpenCV's `BOWImgDescriptorExtractor`. Initialize your BoW model with the feature descriptors from your images.\n",
    "\n",
    "3. **Image Representation**: For each new image, compute its BoW descriptor. This involves mapping its features to the visual words in the BoW model to create a compact representation.\n",
    "\n",
    "### Step 2: Loop Detection\n",
    "\n",
    "1. **Database of Images**: Maintain a database or a simple list of BoW descriptors for each image processed. This database is used to search for potential loop closures.\n",
    "\n",
    "2. **Similarity Measurement**: For each new image, compare its BoW descriptor against those in the database to find potential matches. A high similarity score indicates a potential loop closure.\n",
    "\n",
    "3. **Verification**: Once a potential loop closure is identified, verify it by checking geometric consistency. This could involve matching features between the two images and estimating a transformation to ensure that it aligns with the expected model.\n",
    "\n",
    "### Step 3: Update the Pose Graph\n",
    "\n",
    "1. **Add Loop Closure Edges**: When a loop closure is detected and verified, add a new edge to the pose graph that connects the two nodes (images) involved in the loop closure. The transformation associated with this edge is the relative pose between these two images.\n",
    "\n",
    "    ```python\n",
    "    loop_edge = g2o.EdgeSE3Expmap()\n",
    "    loop_edge.set_vertex(0, optimizer.vertex(loop_start_idx))\n",
    "    loop_edge.set_vertex(1, optimizer.vertex(current_idx))\n",
    "    loop_edge.set_measurement(se3_quat_from_loop_closure)  # SE3Quat of the loop closure transformation\n",
    "    loop_edge.set_information(loop_closure_information_matrix)\n",
    "    optimizer.add_edge(loop_edge)\n",
    "    ```\n",
    "\n",
    "2. **Information Matrix for Loop Closure**: The information matrix for the loop closure edge should reflect your confidence in the loop closure detection. This is typically less confident than the consecutive frame measurements.\n",
    "\n",
    "### Step 4: Re-optimize the Pose Graph\n",
    "\n",
    "After updating the graph with loop closure information, re-optimize the graph to refine the poses of all nodes, taking into account the new loop closure constraints.\n",
    "\n",
    "```python\n",
    "optimizer.initialize_optimization()\n",
    "optimizer.optimize(num_iterations)\n",
    "```\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64add6f8-8449-41dc-b038-74e93db31170",
   "metadata": {},
   "source": [
    "## pyDBoW3\n",
    "\n",
    "### Loading the Vocabulary\n",
    "\n",
    "```python\n",
    "import pyDBoW3 as bow\n",
    "voc = bow.Vocabulary()\n",
    "voc.load(\"/slamdoom/libs/orbslam2/Vocabulary/ORBvoc.txt\")\n",
    "```\n",
    "\n",
    "Loading a pre-trained vocabulary, like the ORB vocabulary from ORB-SLAM2, is a common and effective approach. This step initializes the BoW model with a rich set of visual words that can help in accurately quantifying and matching features across images.\n",
    "\n",
    "### Creating and Configuring the Database\n",
    "\n",
    "```python\n",
    "db = bow.Database()\n",
    "db.setVocabulary(voc, False, 0)\n",
    "del voc  # Freeing vocabulary memory if it's no longer needed\n",
    "```\n",
    "\n",
    "Creating a database and setting the vocabulary is crucial for later querying and matching. The `setVocabulary` method usually has parameters that allow you to control whether the database should use direct index (useful for feature matching) and the maximum number of features to use. Ensure these parameters are set according to your specific needs. The deletion of `voc` after setting the vocabulary is fine if you're looking to free up memory and won't need to access the vocabulary directly later on. However, consider keeping it if you might need to access vocabulary properties or perform operations that require direct vocabulary access.\n",
    "\n",
    "### Feature Extraction and Database Population\n",
    "\n",
    "```python\n",
    "# Assuming `features_list` is a list of feature descriptors extracted from images\n",
    "for features in features_list:\n",
    "    db.add(features)\n",
    "```\n",
    "\n",
    "This loop adds the features extracted from each image to the database, allowing these features to be represented as BoW vectors. It's crucial that `features_list` contains the descriptors in a format that `pyDBoW3` can understand (usually a list or array of descriptors).\n",
    "\n",
    "### Querying the Database\n",
    "\n",
    "```python\n",
    "feature_to_query = 1\n",
    "results = db.query(features_list[feature_to_query], max_results=1)\n",
    "```\n",
    "\n",
    "Querying the database with a set of features to find the best matching images is a key step in detecting loop closures. The `query` method returns a list of tuples `(id, score)`, where `id` is the index of the matching image in the database, and `score` is the similarity score. You might want to adjust the `max_results` parameter based on how many of the top matches you're interested in examining.\n",
    "\n",
    "### Memory Management\n",
    "\n",
    "```python\n",
    "del db  # To explicitly free up database memory\n",
    "```\n",
    "\n",
    "Deleting the database object when it's no longer needed is a good practice, especially in long-running applications, to ensure memory is not unnecessarily held.\n",
    "\n",
    "### Additional Considerations\n",
    "\n",
    "- **Feature Extraction**: The code snippet assumes that feature extraction using OpenCV has been done correctly, and `features_list` contains the descriptors for each image. Ensure that the descriptors are compatible with the BoW model (e.g., ORB descriptors for an ORB vocabulary).\n",
    "\n",
    "- **Loop Closure Verification**: After obtaining potential loop closures from `db.query`, it's important to perform additional geometric verification (e.g., by estimating a homography or a fundamental matrix) to confirm that these closures are valid.\n",
    "\n",
    "- **Parameter Tuning**: Depending on your specific application, you might need to tune parameters related to feature extraction, BoW model creation, and querying to optimize performance and accuracy.\n",
    "\n",
    "Overall, your approach provides a solid foundation for integrating BoW-based loop closure detection into a SLAM system. It leverages `pyDBoW3` for efficient BoW model handling and demonstrates the key steps from vocabulary loading to feature querying, which are essential in practical SLAM applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e35035-4358-416e-aa60-335239dffd1f",
   "metadata": {},
   "source": [
    "## Visualizing SLAM results with Pangolin\n",
    "\n",
    "\n",
    "### Setting Up Pangolin for Visualization\n",
    "\n",
    "First, ensure you have Pangolin installed in your Python environment. The setup might require building from source or installing a pre-built package, depending on the availability for your platform.\n",
    "\n",
    "### Example: Visualizing Camera Poses and Points\n",
    "\n",
    "The following example demonstrates how to initialize a Pangolin window and draw camera poses (as frustums) and 3D points. This is a simplified example to get you started:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pangolin\n",
    "\n",
    "def create_camera(frustum_scale=0.1, frustum_color=[0.0, 1.0, 0.0, 1.0]):\n",
    "    \"\"\"Create a simple camera frustum for visualization.\"\"\"\n",
    "    return np.array([\n",
    "        [0, 0, 0, 1],\n",
    "        [-frustum_scale, -frustum_scale, frustum_scale * 3, 1],\n",
    "        [frustum_scale, -frustum_scale, frustum_scale * 3, 1],\n",
    "        [frustum_scale, frustum_scale, frustum_scale * 3, 1],\n",
    "        [-frustum_scale, frustum_scale, frustum_scale * 3, 1],\n",
    "        [-frustum_scale, -frustum_scale, frustum_scale * 3, 1],\n",
    "    ]), frustum_color\n",
    "\n",
    "def main():\n",
    "    # Initialize Pangolin\n",
    "    pangolin.CreateWindowAndBind('SLAM Visualization', 640, 480)\n",
    "    gl.glEnable(gl.GL_DEPTH_TEST)\n",
    "\n",
    "    # Define Projection and Initial ModelView Matrix\n",
    "    scam = pangolin.OpenGlRenderState(\n",
    "        pangolin.ProjectionMatrix(640, 480, 420, 420, 320, 240, 0.2, 100),\n",
    "        pangolin.ModelViewLookAt(0, -10, -0.1, 0, 0, 0, pangolin.AxisDirection.AxisY))\n",
    "    handler = pangolin.Handler3D(scam)\n",
    "\n",
    "    # Create Interactive View in Window\n",
    "    dcam = pangolin.CreateDisplay()\n",
    "    dcam.SetBounds(0.0, 1.0, pangolin.Attach(0), 1.0, -640.0/480.0)\n",
    "    dcam.SetHandler(handler)\n",
    "\n",
    "    # Camera Poses and Points (Example Data)\n",
    "    camera_poses = [np.eye(4) for _ in range(5)]  # Example camera poses\n",
    "    points = np.random.rand(100, 3)  # Example 3D points\n",
    "\n",
    "    while not pangolin.ShouldQuit():\n",
    "        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n",
    "        gl.glClearColor(1.0, 1.0, 1.0, 1.0)\n",
    "        dcam.Activate(scam)\n",
    "\n",
    "        # Draw Points\n",
    "        pangolin.DrawPoints(points)\n",
    "\n",
    "        # Draw Camera Poses\n",
    "        for pose in camera_poses:\n",
    "            cam, color = create_camera()\n",
    "            pangolin.glDrawColouredCube(pose[:3, :3], pose[:3, 3], 0.1)\n",
    "        \n",
    "        pangolin.FinishFrame()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "\n",
    "### Explanation\n",
    "\n",
    "- **Camera Visualization**: The `create_camera` function generates a simple camera frustum shape. This example simplifies it to drawing a cube representing the camera pose, but you can adjust it to draw a more detailed frustum if needed.\n",
    "\n",
    "- **Main Loop**: Initializes a window, sets up a 3D interactive view, and enters a loop where it clears the screen, activates the camera view, and draws 3D points and camera poses.\n",
    "\n",
    "- **Data**: The `camera_poses` and `points` are placeholder arrays. In a real application, you would update these with the actual camera poses and 3D points from your SLAM system.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
