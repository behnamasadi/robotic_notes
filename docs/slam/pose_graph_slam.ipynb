{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb34fe9-f85a-4891-b7f2-02568ff776a8",
   "metadata": {},
   "source": [
    "# Graph Pose SLAM\n",
    "\n",
    "### **Odometry Data:**\n",
    "From odometry, we typically get the poses $ \\textbf{X}_i $ and $ \\textbf{X}_j $ in the world frame. These poses represent the robot's estimated positions and orientations based on the odometry readings.\n",
    "\n",
    "### **Relative Transformation from Poses:**\n",
    "Using the poses $ \\textbf{X}_i $ and $ \\textbf{X}_j $ in the world frame, we can compute the **predicted relative pose** of $ \\textbf{X}_j $ with respect to $ \\textbf{X}_i $, denoted as $ h(\\textbf{X}_i, \\textbf{X}_j) $. This transformation involves the relative translation and rotation between $ \\textbf{X}_i $ and $ \\textbf{X}_j $.\n",
    "\n",
    "\n",
    "\n",
    "${^{i}_{j}X}$: is the pose of the $j_{th}$farme in $i_{th}$ frame, to get the pose of the robot from world coordinate in the $i_{th}$ frame: \n",
    "\n",
    " <img src=\"https://latex.codecogs.com/svg.latex?%7B%5E%7Bi%7D_%7Bj%7DX%7D%3D%28%7B%5E%7Bw%7D_%7Bi%7DT%20%5E%7B-1%7D%7D%20%29%5Ctimes%20%28%20%7B%5E%7Bw%7D_%7Bj%7DX%7D%29\" alt=\"https://latex.codecogs.com/svg.latex?{^{i}_{j}X}=({^{w}_{i}T ^{-1}} )\\times ( {^{w}_{j}X})\" />\n",
    "\n",
    "which is:\n",
    "\n",
    " <img src=\"https://latex.codecogs.com/svg.latex?%7B%5E%7Bi%7D_%7Bj%7DX%7D%3D%20%5Cbegin%7Bbmatrix%7D%20%7B%5E%7Bw%7D_%7Bi%7DR%7D%5ET%20%26%20-%7B%5E%7Bw%7D_%7Bi%7DR%7D%5ET%20%5Ctimes%20%28%7B%5E%7Bw%7D_%7Bi%7DP%7D%29%20%5C%5C%200%20%26%201%20%5Cend%7Bbmatrix%7D%20%5Ctimes%20%28%20%7B%5E%7Bw%7D_%7Bj%7DX%7D%29\" alt=\"https://latex.codecogs.com/svg.latex?{^{i}_{j}X}= \\begin{bmatrix}\n",
    "{^{w}_{i}R}^T &   -{^{w}_{i}R}^T \\times ({^{w}_{i}P})  \\\\ \n",
    "0 & 1  \n",
    "\\end{bmatrix} \\times ( {^{w}_{j}X})\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f565c58-9316-4fe5-a0f8-0579df84c3ae",
   "metadata": {},
   "source": [
    "Just like what we did to bring point in the world coordinate to camera coordinate, we can do the same here:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%7B%5E%7Bi%7D_%7Bj%7DR%7D%3D%28%7B%5E%7Bw%7D_%7Bi%7DR%20%5ET%7D%20%29%5Ctimes%20%28%20%7B%5E%7Bw%7D_%7Bj%7DR%7D%29\" alt=\"https://latex.codecogs.com/svg.latex?{^{i}_{j}R}=({^{w}_{i}R ^T} )\\times ( {^{w}_{j}R})\" />\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5E%7Bi%7D_jP%3D%5E%7Bw%7D_iR%5ET%20%28%20%7B%5E%7Bw%7D_%7Bj%7DP%7D%20-%7B%5E%7Bw%7D_%7Bi%7DP%7D%20%29\" alt=\"https://latex.codecogs.com/svg.latex?^{i}_jP=^{w}_iR^T (  {^{w}_{j}P} -{^{w}_{i}P} ) \" />\n",
    "\n",
    "which gives us: \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5Cbegin%7Bbmatrix%7D%20%5E%7Bi%7D_j%20x%20%5C%5C%20%5E%7Bi%7D_j%20y%20%5Cend%7Bbmatrix%7D%3D%5Cbegin%7Bbmatrix%7D%20cos%28i%5Ew%20%5Ctheta%20%29%20%26%20sin%28i%5Ew%20%5Ctheta%20%29%20%5C%5C%20-sin%28i%5Ew%20%5Ctheta%20%29%20%26%20cos%28i%5Ew%20%5Ctheta%29%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5E%7Bw%7D_jx%20-%20%5E%7Bw%7D_ix%20%5C%5C%20%5E%7Bw%7D_jy%20-%20%5E%7Bw%7D_iy%20%5Cend%7Bbmatrix%7D\" alt=\"https://latex.codecogs.com/svg.latex?\\begin{bmatrix} ^{i}_j x \\\\  ^{i}_j y \\end{bmatrix}=\\begin{bmatrix} cos(i^w \\theta ) & sin(i^w \\theta ) \\\\ -sin(i^w \\theta ) & cos(i^w \\theta) \\end{bmatrix} \\begin{bmatrix} ^{w}_jx - ^{w}_ix \\\\  ^{w}_jy - ^{w}_iy \\end{bmatrix}\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?%5E%7Bi%7D_j%20%5Ctheta%20%3D%5E%7Bw%7D_j%5Ctheta%20-%7B%5E%7Bw%7D_%7Bi%7D%5Ctheta%7D\" alt=\"https://latex.codecogs.com/svg.latex?^{i}_j \\theta =^{w}_j\\theta -{^{w}_{i}\\theta}\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9ed67-59d8-4d2d-92bc-c27698866919",
   "metadata": {},
   "source": [
    "### **Sensor Measurements:**\n",
    "From the sensor (e.g., a laser scanner or camera), we obtain a measurement $ z_{ij} $, which represents the **observed relative pose** of $ \\textbf{X}_j $ with respect to $ \\textbf{X}_i $. This measurement typically includes relative position and orientation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffafaa9-d3e0-4a38-a3bc-5782cf77b51a",
   "metadata": {},
   "source": [
    "### State Vector\n",
    "The state vector $ \\mathbb{X} $ contains the 2D poses of all $ n $ nodes:\n",
    "\n",
    "$\n",
    "\\mathbb{X} = (x_1, y_1, \\theta_1, x_2, y_2, \\theta_2, \\dots, x_n, y_n, \\theta_n)\n",
    "$\n",
    "\n",
    "Each pose $ \\textbf{X}_i = (x_i, y_i, \\theta_i) $ represents the position and orientation of a node.\n",
    "\n",
    "---\n",
    "\n",
    "### **Error Function:**\n",
    "\n",
    "The error function compares the **predicted relative pose** $ h(\\textbf{X}_i, \\textbf{X}_j) $ (computed from odometry poses) to the **observed relative pose** $ z_{ij} $ (sensor measurement):\n",
    "\n",
    "$e_{ij} = z_{ij} - h(\\textbf{X}_i, \\textbf{X}_j)$\n",
    "\n",
    "\n",
    "$\n",
    "\\textbf{e}_{ij}(\\mathbb{X}) = \\textbf{e}_{ij}(\\textbf{X}_i, \\textbf{X}_j)\n",
    "$\n",
    "\n",
    "Where the components of $ \\textbf{e}_{ij} $ are given by:\n",
    "\n",
    "$\n",
    "\\textbf{e}_{ij}(\\textbf{X}_i, \\textbf{X}_j) = \n",
    "\\begin{bmatrix}\n",
    "^i_jx \\\\ \n",
    "^i_jy \\\\ \n",
    "^{i}_j \\theta \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\cos(\\theta_i)(x_j - x_i) + \\sin(\\theta_i)(y_j - y_i) - z_x \\\\\n",
    "-\\sin(\\theta_i)(x_j - x_i) + \\cos(\\theta_i)(y_j - y_i) - z_y \\\\\n",
    "\\theta_j - \\theta_i - z_\\theta\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Here:\n",
    "- $ z_x, z_y, z_\\theta $ are the observed relative pose measurements.\n",
    "- $ x_j, y_j, \\theta_j $ and $ x_i, y_i, \\theta_i $ are the current estimates of the poses.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd9c14-0a5c-47f9-a64d-154b1fad8490",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Linearization of the Error Function**\n",
    "The error function for an edge $ij$ is:\n",
    "\n",
    "$\n",
    "e_{ij} = z_{ij} - h(\\textbf{X}_i, \\textbf{X}_j)\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ z_{ij} = \\begin{bmatrix} z_x \\\\ z_y \\\\ z_\\theta \\end{bmatrix} $ is the observed relative pose.\n",
    "- $ h(\\textbf{X}_i, \\textbf{X}_j) $ is the predicted relative pose computed from the current estimate of $ \\textbf{X}_i $ and $ \\textbf{X}_j $:\n",
    "\n",
    "$\n",
    "h(\\textbf{X}_i, \\textbf{X}_j) =\n",
    "\\begin{bmatrix}\n",
    "\\cos(\\theta_i)(x_j - x_i) + \\sin(\\theta_i)(y_j - y_i) \\\\\n",
    "-\\sin(\\theta_i)(x_j - x_i) + \\cos(\\theta_i)(y_j - y_i) \\\\\n",
    "\\theta_j - \\theta_i\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "We linearize $ e_{ij} $ around the **current estimate** using a first-order Taylor expansion:\n",
    "\n",
    "$\n",
    "e_{ij} \\approx e_{ij}^k + J_i \\Delta \\textbf{X}_i + J_j \\Delta \\textbf{X}_j\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ e_{ij}^k = z_{ij} - h(\\textbf{X}_i^k, \\textbf{X}_j^k) $ is the error at the current estimate.\n",
    "- $ J_i = \\frac{\\partial e_{ij}}{\\partial \\textbf{X}_i} $ and $ J_j = \\frac{\\partial e_{ij}}{\\partial \\textbf{X}_j} $ are the Jacobians.\n",
    "\n",
    "---\n",
    "\n",
    "### **Jacobians: $ J_i $ and $ J_j $**\n",
    "The Jacobians are derived by taking the partial derivatives of $ e_{ij} $ with respect to $ \\textbf{X}_i $ and $ \\textbf{X}_j $. For the predicted relative pose $ h(\\textbf{X}_i, \\textbf{X}_j) $, we compute:\n",
    "\n",
    "#### 1. Jacobian with respect to $ \\textbf{X}_i $ ($ J_i $):\n",
    "\n",
    "$\n",
    "J_i =\n",
    "\\begin{bmatrix}\n",
    "-\\cos(\\theta_i) & -\\sin(\\theta_i) & -\\sin(\\theta_i)(x_j - x_i) + \\cos(\\theta_i)(y_j - y_i) \\\\\n",
    "\\sin(\\theta_i) & -\\cos(\\theta_i) & -\\cos(\\theta_i)(x_j - x_i) - \\sin(\\theta_i)(y_j - y_i) \\\\\n",
    "0 & 0 & -1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "#### 2. Jacobian with respect to $ \\textbf{X}_j $ ($ J_j $):\n",
    "\n",
    "$\n",
    "J_j =\n",
    "\\begin{bmatrix}\n",
    "\\cos(\\theta_i) & \\sin(\\theta_i) & 0 \\\\\n",
    "-\\sin(\\theta_i) & \\cos(\\theta_i) & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### **Information Matrix $H$ and Residual Vector $b$**\n",
    "We use the linearized error function in the least-squares formulation. The goal is to minimize:\n",
    "\n",
    "$\n",
    "E = \\frac{1}{2} \\sum_{ij} e_{ij}^T \\Omega_{ij} e_{ij}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ \\Omega_{ij} $ is the **information matrix** (inverse of the measurement covariance matrix).\n",
    "\n",
    "#### Expanding $E$:\n",
    "Substituting the linearized error $ e_{ij} \\approx e_{ij}^k + J_i \\Delta \\textbf{X}_i + J_j \\Delta \\textbf{X}_j $:\n",
    "\n",
    "$\n",
    "E \\approx \\frac{1}{2} \\sum_{ij} \\left( e_{ij}^k + J_i \\Delta \\textbf{X}_i + J_j \\Delta \\textbf{X}_j \\right)^T \\Omega_{ij} \\left( e_{ij}^k + J_i \\Delta \\textbf{X}_i + J_j \\Delta \\textbf{X}_j \\right)\n",
    "$\n",
    "\n",
    "#### Quadratic Expansion:\n",
    "After expanding and keeping only the terms relevant to optimization:\n",
    "\n",
    "$\n",
    "E \\approx \\frac{1}{2} \\sum_{ij} \\left( (e_{ij}^k)^T \\Omega_{ij} e_{ij}^k + 2(e_{ij}^k)^T \\Omega_{ij} (J_i \\Delta \\textbf{X}_i + J_j \\Delta \\textbf{X}_j) + \\Delta \\textbf{X}^T H_{ij} \\Delta \\textbf{X} \\right)\n",
    "$\n",
    "\n",
    "Where $ H_{ij} = J_i^T \\Omega_{ij} J_i + J_j^T \\Omega_{ij} J_j + J_i^T \\Omega_{ij} J_j + J_j^T \\Omega_{ij} J_i $.\n",
    "\n",
    "#### Global $H$ and $b$:\n",
    "The contributions to the global $ H $ (information matrix) and $ b $ (residual vector) are:\n",
    "\n",
    "1. **Information Matrix $ H $:**\n",
    "   - Add contributions for all edges:\n",
    "     $\n",
    "     H = \\sum_{ij} J_i^T \\Omega_{ij} J_i + J_j^T \\Omega_{ij} J_j + J_i^T \\Omega_{ij} J_j + J_j^T \\Omega_{ij} J_i\n",
    "     $\n",
    "\n",
    "2. **Residual Vector $ b $:**\n",
    "   - Add contributions for all edges:\n",
    "     $\n",
    "     b = \\sum_{ij} -J_i^T \\Omega_{ij} e_{ij}^k - J_j^T \\Omega_{ij} e_{ij}^k\n",
    "     $\n",
    "\n",
    "---\n",
    "\n",
    "### Final System:\n",
    "The optimization problem becomes solving the linear system:\n",
    "\n",
    "$\n",
    "H \\Delta \\textbf{X} = b\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ \\Delta \\textbf{X} $ is the pose correction vector.\n",
    "- $ H $ is the global sparse information matrix.\n",
    "- $ b $ is the global residual vector.\n",
    "\n",
    "This system can be solved iteratively using methods like Gauss-Newton or Levenberg-Marquardt until the corrections $ \\Delta \\textbf{X} $ are sufficiently small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe7632-e0e8-4a43-8d93-dc4a3d6c5222",
   "metadata": {},
   "source": [
    "### Jacobians and Linearization\n",
    "To linearize the error function, we compute its Jacobian with respect to the poses $x_i$ and $x_j$:\n",
    "\n",
    "$\n",
    "e_{ij} \\approx e_{ij}(x_i^k, x_j^k) + J_i \\Delta x_i + J_j \\Delta x_j\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $x_i^k$ and $x_j^k$ are the current estimates of the poses,\n",
    "- $\\Delta x_i$ and $\\Delta x_j$ are the pose corrections,\n",
    "- $J_i = \\frac{\\partial e_{ij}}{\\partial x_i}$ and $J_j = \\frac{\\partial e_{ij}}{\\partial x_j}$ are the Jacobians of the error function with respect to $x_i$ and $x_j$.\n",
    "\n",
    "### Building $H$ and $b$\n",
    "The contributions to the information matrix ($H$) and residual vector ($b$) are derived from the squared error:\n",
    "\n",
    "$\n",
    "e_{ij}^T \\Omega_{ij} e_{ij}\n",
    "$\n",
    "\n",
    "Where $\\Omega_{ij}$ is the information matrix for the edge $ij$ (inverse of the measurement covariance matrix).\n",
    "\n",
    "The contributions to $H$ and $b$ are computed as:\n",
    "\n",
    "1. **Residual Vector ($b$):**\n",
    "\n",
    "   $\n",
    "   b_i = - J_i^T \\Omega_{ij} e_{ij}\n",
    "   $\n",
    "   $\n",
    "   b_j = - J_j^T \\Omega_{ij} e_{ij}\n",
    "   $\n",
    "\n",
    "   These are summed into the global residual vector.\n",
    "\n",
    "2. **Information Matrix ($H$):**\n",
    "\n",
    "   $\n",
    "   H_{ii} = J_i^T \\Omega_{ij} J_i\n",
    "   $\n",
    "   $\n",
    "   H_{ij} = J_i^T \\Omega_{ij} J_j\n",
    "   $\n",
    "   $\n",
    "   H_{jj} = J_j^T \\Omega_{ij} J_j\n",
    "   $\n",
    "\n",
    "   These are summed into the global $H$, which is a sparse matrix.\n",
    "\n",
    "### Summary Equation\n",
    "The global least-squares problem becomes:\n",
    "\n",
    "$\n",
    "H \\Delta x = b\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $H$ is the global information matrix,\n",
    "- $\\Delta x$ is the vector of pose corrections,\n",
    "- $b$ is the global residual vector.\n",
    "\n",
    "This system can be solved iteratively (e.g., using Gauss-Newton or Levenberg-Marquardt) to update the pose estimates and minimize the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae95514-e973-4626-a4d5-a7e4d6b743c8",
   "metadata": {},
   "source": [
    "For this error, function, which is a function of 6 variables, $(x_i,y_i,\\theta_i,x_j,y_j,\\theta_j)$, the $J_{ij}$ element of the jacobian matrix is:\n",
    "\n",
    "$\\\\ J_{ij}=\\begin{bmatrix} 0 & ... & 0 & \\frac{\\partial ^{i}_jx}{ \\partial _{i} x}      &  \\frac{\\partial ^{i}_jx}{ \\partial _{i} y}  & \\frac{\\partial ^{i}_j x}{ \\partial _{i} \\theta} &0 &... & \\frac{\\partial ^{i}_jx}{ \\partial _{j} x}      &  \\frac{\\partial ^{i}_jx}{ \\partial _{j} y}  & \\frac{\\partial ^{i}_j x}{ \\partial _{j} \\theta}  &... &0\\\\ 0 & ... & 0 & \\frac{\\partial ^{i}_jy}{ \\partial _{i} x} &  \\frac{\\partial ^{i}_jy}{ \\partial _{i} y}  & \\frac{\\partial ^{i}_j y}{ \\partial _{i} \\theta} &0   &...& \\frac{\\partial ^{i}_jy}{ \\partial _{j} x} &  \\frac{\\partial ^{i}_jy}{ \\partial _{j} y}  & \\frac{\\partial ^{i}_j y}{ \\partial _{j} \\theta}& ...     & 0\\\\ 0 & ... & 0 & \\frac{\\partial ^{i}_j\\theta}{ \\partial _{i} x}      &  \\frac{\\partial ^{i}_j\\theta}{ \\partial _{i} y}  & \\frac{\\partial ^{i}_j \\theta}{ \\partial _{i} \\theta} &0 &...&\\frac{\\partial ^{i}_j\\theta}{ \\partial _{j} x}      &  \\frac{\\partial ^{i}_j\\theta}{ \\partial _{j} y}  & \\frac{\\partial ^{i}_j \\theta}{ \\partial _{j} \\theta} &...  & 0\\\\ \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e9e98-e546-432c-9843-407b79be7f0f",
   "metadata": {},
   "source": [
    "$A_{i,j}=  \\frac{ \\partial   \\textbf{e}(\\textbf{X}_{i})}{  \\partial  \\textbf{X}_{j}  }      $\n",
    "\n",
    "\n",
    "\n",
    "$A_{ij}=\\begin{bmatrix}  \\frac{\\partial ^{i}_jx}{ \\partial _{i} x}      &  \\frac{\\partial ^{i}_jx}{ \\partial _{i} y}  & \\frac{\\partial ^{i}_j x}{ \\partial _{i} \\theta} \\\\ \\frac{\\partial ^{i}_jy}{ \\partial _{i} x} &  \\frac{\\partial ^{i}_jy}{ \\partial _{i} y}  & \\frac{\\partial ^{i}_j y}{ \\partial _{i} \\theta} \\\\ \\frac{\\partial ^{i}_j\\theta}{ \\partial _{i} x}      &  \\frac{\\partial ^{i}_j\\theta}{ \\partial _{i} y}  & \\frac{\\partial ^{i}_j \\theta}{ \\partial _{i} \\theta} \\\\ \\end{bmatrix}$\n",
    "\n",
    "\n",
    "$A_{i,j}=\\begin{bmatrix} -cos(\\theta_i) & -sin(\\theta_i)  & -sin(\\theta_i)(x_j-x_i)+cos(\\theta_i)(y_j-y_i)\\\\ sin(\\theta_i) & -cos(\\theta_i) & -cos(\\theta_i)(x_j-x_i) - sin(\\theta_i)(y_j-y_i)\\\\ 0 & 0 & -1 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7f514-c9f5-4c16-9b67-80cc72767fc0",
   "metadata": {},
   "source": [
    "<img src=\"https://latex.codecogs.com/svg.latex?B_%7Bi%2Cj%7D%3D%5Cbegin%7Bbmatrix%7D%20cos%28%5Ctheta_i%29%20%26%20-sin%28%5Ctheta_i%29%20%26%200%5C%5C%20-sin%28%5Ctheta_i%29%20%26%20cos%28%5Ctheta_i%29%20%26%200%5C%5C%200%20%26%200%20%26%201%20%5Cend%7Bbmatrix%7D\" alt=\"https://latex.codecogs.com/svg.latex?B_{i,j}=\\begin{bmatrix} cos(\\theta_i) & -sin(\\theta_i)  & 0\\\\  -sin(\\theta_i) & cos(\\theta_i) & 0\\\\  0 & 0 & 1 \\end{bmatrix}\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb691de3-30f0-4c11-b161-18f8a487cf63",
   "metadata": {},
   "source": [
    "\n",
    "### 1. **Error Function and its Variables**\n",
    "The error function depends only on the poses $(x_i, y_i, \\theta_i, x_j, y_j, \\theta_j)$. Since $z_x$, $z_y$, and $z_\\theta$ are constants (observed measurements), they do not influence the derivatives, and hence they do not appear in the Jacobian.\n",
    "\n",
    "Since the measurements $z_x, z_y, z_\\theta$ are constants and do not depend on the state variables $(x_i, y_i, \\theta_i, x_j, y_j, \\theta_j)$, they do not appear in the derivatives. This is correct, and the Jacobian depends solely on the current estimates of the state variables.\n",
    "\n",
    "\n",
    "### 2. **Jacobian Matrix Structure**\n",
    "The Jacobian $J_{ij}$ matrix provided correctly represents the structure of the derivatives of the error function with respect to the state variables. The detailed form:\n",
    "\n",
    "$\n",
    "J_{ij} = \n",
    "\\begin{bmatrix}\n",
    "0 & \\cdots & 0 & \\frac{\\partial e_{x}}{\\partial x_i} & \\frac{\\partial e_{x}}{\\partial y_i} & \\frac{\\partial e_{x}}{\\partial \\theta_i} & 0 & \\cdots & 0 & \\frac{\\partial e_{x}}{\\partial x_j} & \\frac{\\partial e_{x}}{\\partial y_j} & \\frac{\\partial e_{x}}{\\partial \\theta_j} & \\cdots & 0 \\\\\n",
    "0 & \\cdots & 0 & \\frac{\\partial e_{y}}{\\partial x_i} & \\frac{\\partial e_{y}}{\\partial y_i} & \\frac{\\partial e_{y}}{\\partial \\theta_i} & 0 & \\cdots & 0 & \\frac{\\partial e_{y}}{\\partial x_j} & \\frac{\\partial e_{y}}{\\partial y_j} & \\frac{\\partial e_{y}}{\\partial \\theta_j} & \\cdots & 0 \\\\\n",
    "0 & \\cdots & 0 & \\frac{\\partial e_{\\theta}}{\\partial x_i} & \\frac{\\partial e_{\\theta}}{\\partial y_i} & \\frac{\\partial e_{\\theta}}{\\partial \\theta_i} & 0 & \\cdots & 0 & \\frac{\\partial e_{\\theta}}{\\partial x_j} & \\frac{\\partial e_{\\theta}}{\\partial y_j} & \\frac{\\partial e_{\\theta}}{\\partial \\theta_j} & \\cdots & 0\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "### 3. **Jacobian Block Structure**\n",
    "The block $A_{ij}$ represents the partial derivatives of the error function with respect to the individual pose variables. Its structure is correctly described as:\n",
    "\n",
    "$\n",
    "A_{ij} =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial e_x}{\\partial x_i} & \\frac{\\partial e_x}{\\partial y_i} & \\frac{\\partial e_x}{\\partial \\theta_i} \\\\\n",
    "\\frac{\\partial e_y}{\\partial x_i} & \\frac{\\partial e_y}{\\partial y_i} & \\frac{\\partial e_y}{\\partial \\theta_i} \\\\\n",
    "\\frac{\\partial e_{\\theta}}{\\partial x_i} & \\frac{\\partial e_{\\theta}}{\\partial y_i} & \\frac{\\partial e_{\\theta}}{\\partial \\theta_i}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "### 4. **Jacobian for $A_{i,j}$**\n",
    "The specific Jacobian block for $A_{i,j}$ (with respect to $\\textbf{X}_i$) is:\n",
    "\n",
    "$\n",
    "A_{i,j} = \n",
    "\\begin{bmatrix}\n",
    "-\\cos(\\theta_i) & -\\sin(\\theta_i) & -\\sin(\\theta_i)(x_j-x_i) + \\cos(\\theta_i)(y_j-y_i) \\\\\n",
    "\\sin(\\theta_i) & -\\cos(\\theta_i) & -\\cos(\\theta_i)(x_j-x_i) - \\sin(\\theta_i)(y_j-y_i) \\\\\n",
    "0 & 0 & -1\n",
    "\\end{bmatrix}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a3064-560d-413e-a8bd-83beeb465385",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$ B_{ij} = \\frac{\\partial \\textbf{e}_{ij}}{\\partial \\textbf{X}_j} $\n",
    "The error function is:\n",
    "\n",
    "$\n",
    "\\textbf{e}_{ij}(\\textbf{X}_i, \\textbf{X}_j) = \n",
    "\\begin{bmatrix}\n",
    "^i_jx \\\\\n",
    "^i_jy \\\\\n",
    "^i_j\\theta\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Where:\n",
    "\n",
    "$\n",
    "^i_jx = \\cos(\\theta_i)(x_j - x_i) + \\sin(\\theta_i)(y_j - y_i)\n",
    "$\n",
    "$\n",
    "^i_jy = -\\sin(\\theta_i)(x_j - x_i) + \\cos(\\theta_i)(y_j - y_i)\n",
    "$\n",
    "$\n",
    "^i_j\\theta = \\theta_j - \\theta_i\n",
    "$\n",
    "\n",
    "#### Partial Derivatives for $ B_{ij} $\n",
    "The Jacobian with respect to $ \\textbf{X}_j = (x_j, y_j, \\theta_j) $ is:\n",
    "\n",
    "$\n",
    "B_{ij} = \\frac{\\partial \\textbf{e}_{ij}}{\\partial \\textbf{X}_j} =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial ^i_jx}{\\partial x_j} & \\frac{\\partial ^i_jx}{\\partial y_j} & \\frac{\\partial ^i_jx}{\\partial \\theta_j} \\\\\n",
    "\\frac{\\partial ^i_jy}{\\partial x_j} & \\frac{\\partial ^i_jy}{\\partial y_j} & \\frac{\\partial ^i_jy}{\\partial \\theta_j} \\\\\n",
    "\\frac{\\partial ^i_j\\theta}{\\partial x_j} & \\frac{\\partial ^i_j\\theta}{\\partial y_j} & \\frac{\\partial ^i_j\\theta}{\\partial \\theta_j}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "#### Computing Each Partial Derivative\n",
    "1. For $ ^i_jx $:\n",
    "   $\n",
    "   \\frac{\\partial ^i_jx}{\\partial x_j} = \\cos(\\theta_i), \\quad\n",
    "   \\frac{\\partial ^i_jx}{\\partial y_j} = \\sin(\\theta_i), \\quad\n",
    "   \\frac{\\partial ^i_jx}{\\partial \\theta_j} = 0\n",
    "   $\n",
    "\n",
    "2. For $ ^i_jy $:\n",
    "   $\n",
    "   \\frac{\\partial ^i_jy}{\\partial x_j} = -\\sin(\\theta_i), \\quad\n",
    "   \\frac{\\partial ^i_jy}{\\partial y_j} = \\cos(\\theta_i), \\quad\n",
    "   \\frac{\\partial ^i_jy}{\\partial \\theta_j} = 0\n",
    "   $\n",
    "\n",
    "3. For $ ^i_j\\theta $:\n",
    "   $\n",
    "   \\frac{\\partial ^i_j\\theta}{\\partial x_j} = 0, \\quad\n",
    "   \\frac{\\partial ^i_j\\theta}{\\partial y_j} = 0, \\quad\n",
    "   \\frac{\\partial ^i_j\\theta}{\\partial \\theta_j} = 1\n",
    "   $\n",
    "\n",
    "#### Final Form of $ B_{ij} $\n",
    "$\n",
    "B_{ij} =\n",
    "\\begin{bmatrix}\n",
    "\\cos(\\theta_i) & \\sin(\\theta_i) & 0 \\\\\n",
    "-\\sin(\\theta_i) & \\cos(\\theta_i) & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e448cd-4456-4caa-b575-549ade4f4156",
   "metadata": {},
   "source": [
    "### Jacobians for Linearization\n",
    "The error function is linearized around the current estimate using the Jacobians with respect to $ \\textbf{X}_i $ and $ \\textbf{X}_j $. The Jacobians are:\n",
    "\n",
    "$\n",
    "J_i = \\frac{\\partial \\textbf{e}_{ij}}{\\partial \\textbf{X}_i}, \\quad\n",
    "J_j = \\frac{\\partial \\textbf{e}_{ij}}{\\partial \\textbf{X}_j}\n",
    "$\n",
    "\n",
    "#### Jacobian with respect to $ \\textbf{X}_i $:\n",
    "$\n",
    "J_i =\n",
    "\\begin{bmatrix}\n",
    "-\\cos(\\theta_i) & -\\sin(\\theta_i) & -\\sin(\\theta_i)(x_j - x_i) + \\cos(\\theta_i)(y_j - y_i) \\\\\n",
    "\\sin(\\theta_i) & -\\cos(\\theta_i) & -\\cos(\\theta_i)(x_j - x_i) - \\sin(\\theta_i)(y_j - y_i) \\\\\n",
    "0 & 0 & -1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "#### Jacobian with respect to $ \\textbf{X}_j $:\n",
    "$\n",
    "J_j =\n",
    "\\begin{bmatrix}\n",
    "\\cos(\\theta_i) & \\sin(\\theta_i) & 0 \\\\\n",
    "-\\sin(\\theta_i) & \\cos(\\theta_i) & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### Building $ b $ and $ H $\n",
    "For each edge $ ij $, the contributions to the residual vector $ b $ and information matrix $ H $ are computed as:\n",
    "\n",
    "1. **Residual Vector Contribution ($ b $):**\n",
    "\n",
    "$\n",
    "b_i = - J_i^T \\Omega_{ij} \\textbf{e}_{ij}, \\quad b_j = - J_j^T \\Omega_{ij} \\textbf{e}_{ij}\n",
    "$\n",
    "\n",
    "Where $ \\Omega_{ij} $ is the information matrix for the measurement $ z_{ij} $ (inverse of its covariance).\n",
    "\n",
    "2. **Information Matrix Contribution ($ H $):**\n",
    "\n",
    "$\n",
    "H_{ii} = J_i^T \\Omega_{ij} J_i, \\quad\n",
    "H_{ij} = J_i^T \\Omega_{ij} J_j, \\quad\n",
    "H_{jj} = J_j^T \\Omega_{ij} J_j\n",
    "$\n",
    "\n",
    "These contributions are summed into the global matrix $ H $ and vector $ b $ for all edges.\n",
    "\n",
    "---\n",
    "\n",
    "### Final System\n",
    "After aggregating contributions from all edges, the optimization problem can be expressed as:\n",
    "\n",
    "$\n",
    "H \\Delta \\mathbb{X} = b\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ H $ is the global sparse information matrix,\n",
    "- $ \\Delta \\mathbb{X} $ is the correction to the current pose estimates,\n",
    "- $ b $ is the global residual vector.\n",
    "\n",
    "This system is solved iteratively (e.g., using Gauss-Newton or Levenberg-Marquardt) to update $ \\mathbb{X} $ and minimize the total error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324caf15-e7ed-4139-b7a9-6d04d36cd781",
   "metadata": {},
   "source": [
    "Let’s explicitly derive the components of $ H_{ii} $, $ H_{ij} $, $ b_{ii} $, and $ b_{ij} $ for the linearized system.\n",
    "\n",
    "---\n",
    "\n",
    "### **From the Linearized Error Function**\n",
    "The linearized error function is:\n",
    "\n",
    "$\n",
    "e_{ij} \\approx e_{ij}^k + J_i \\Delta \\textbf{X}_i + J_j \\Delta \\textbf{X}_j\n",
    "$\n",
    "\n",
    "The energy function for the least-squares problem is:\n",
    "\n",
    "$\n",
    "E = \\frac{1}{2} \\sum_{ij} e_{ij}^T \\Omega_{ij} e_{ij}\n",
    "$\n",
    "\n",
    "Expanding $E$ using the linearized error:\n",
    "\n",
    "$\n",
    "E \\approx \\frac{1}{2} \\sum_{ij} \\left( e_{ij}^k + J_i \\Delta \\textbf{X}_i + J_j \\Delta \\textbf{X}_j \\right)^T \\Omega_{ij} \\left( e_{ij}^k + J_i \\Delta \\textbf{X}_i + J_j \\Delta \\textbf{X}_j \\right)\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### **Derivation of $ H_{ii} $, $ H_{ij} $, $ b_{ii} $, $ b_{ij} $**\n",
    "By collecting terms in the quadratic form, we get:\n",
    "\n",
    "1. **Information Matrix $H_{ii}$:**\n",
    "   Contribution from pose $ \\textbf{X}_i $ for edge $ ij $:\n",
    "   $\n",
    "   H_{ii} = J_i^T \\Omega_{ij} J_i\n",
    "   $\n",
    "\n",
    "2. **Information Matrix $H_{ij}$:**\n",
    "   Cross-term contribution between poses $ \\textbf{X}_i $ and $ \\textbf{X}_j $:\n",
    "   $\n",
    "   H_{ij} = J_i^T \\Omega_{ij} J_j\n",
    "   $\n",
    "\n",
    "   Note: $ H_{ij} $ is not diagonal—it represents the coupling between the two poses.\n",
    "\n",
    "3. **Residual Vector $b_i$:**\n",
    "   Contribution from pose $ \\textbf{X}_i $ to the residual vector:\n",
    "   $\n",
    "   b_i = -J_i^T \\Omega_{ij} e_{ij}^k\n",
    "   $\n",
    "\n",
    "4. **Residual Vector $b_j$:**\n",
    "   Contribution from pose $ \\textbf{X}_j $ to the residual vector:\n",
    "   $\n",
    "   b_j = -J_j^T \\Omega_{ij} e_{ij}^k\n",
    "   $\n",
    "\n",
    "---\n",
    "\n",
    "### **Explicit Components**\n",
    "\n",
    "Using the previously derived Jacobians for $ J_i $ and $ J_j $, we can compute $ H_{ii} $, $ H_{ij} $, $ b_i $, and $ b_j $.\n",
    "\n",
    "1. **$H_{ii}$:**\n",
    "   $\n",
    "   H_{ii} = J_i^T \\Omega_{ij} J_i\n",
    "   $\n",
    "   Substituting $ J_i $ (as derived earlier):\n",
    "   $\n",
    "   J_i =\n",
    "   \\begin{bmatrix}\n",
    "   -\\cos(\\theta_i) & -\\sin(\\theta_i) & -\\sin(\\theta_i)(x_j - x_i) + \\cos(\\theta_i)(y_j - y_i) \\\\\n",
    "   \\sin(\\theta_i) & -\\cos(\\theta_i) & -\\cos(\\theta_i)(x_j - x_i) - \\sin(\\theta_i)(y_j - y_i) \\\\\n",
    "   0 & 0 & -1\n",
    "   \\end{bmatrix}\n",
    "   $\n",
    "\n",
    "   Multiply $ J_i^T $ and $ J_i $, weighted by $ \\Omega_{ij} $.\n",
    "\n",
    "2. **$H_{ij}$:**\n",
    "   $\n",
    "   H_{ij} = J_i^T \\Omega_{ij} J_j\n",
    "   $\n",
    "   Substituting $ J_i $ and $ J_j $:\n",
    "   $\n",
    "   J_j =\n",
    "   \\begin{bmatrix}\n",
    "   \\cos(\\theta_i) & \\sin(\\theta_i) & 0 \\\\\n",
    "   -\\sin(\\theta_i) & \\cos(\\theta_i) & 0 \\\\\n",
    "   0 & 0 & 1\n",
    "   \\end{bmatrix}\n",
    "   $\n",
    "\n",
    "   Multiply $ J_i^T $ and $ J_j $, weighted by $ \\Omega_{ij} $.\n",
    "\n",
    "3. **$b_{i}$:**\n",
    "   $\n",
    "   b_{i} = -J_i^T \\Omega_{ij} e_{ij}^k\n",
    "   $\n",
    "   Substituting $ J_i $ and $ e_{ij}^k $:\n",
    "   $\n",
    "   e_{ij}^k = z_{ij} - h(\\textbf{X}_i, \\textbf{X}_j)\n",
    "   $\n",
    "\n",
    "4. **$b_{j}$:**\n",
    "   $\n",
    "   b_{j} = -J_j^T \\Omega_{ij} e_{ij}^k\n",
    "   $\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Key Terms\n",
    "\n",
    "- $H_{ii} = J_i^T \\Omega_{ij} J_i$\n",
    "- $H_{ij} = J_i^T \\Omega_{ij} J_j$\n",
    "- $b_{i} = -J_i^T \\Omega_{ij} e_{ij}^k$\n",
    "- $b_{j} = -J_j^T \\Omega_{ij} e_{ij}^k$\n",
    "\n",
    "These contributions are summed over all edges $ij$ in the graph to form the global $H$ and $b$:\n",
    "\n",
    "$\n",
    "H = \\sum_{ij} \\begin{bmatrix}\n",
    "H_{ii} & H_{ij} \\\\\n",
    "H_{ji} & H_{jj}\n",
    "\\end{bmatrix}, \\quad\n",
    "b = \\sum_{ij} \\begin{bmatrix}\n",
    "b_{i} \\\\\n",
    "b_{j}\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f056b-c660-415a-9367-7be1ca20af2b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"images/J_i_j.png\"  width= \"50%\"  height= \"50%\"/>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<img src=\"images/b_h.png\" width= \"50%\"  height= \"50%\"/>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<img src=\"images/b_i_j_h_i_j.png\" width= \"50%\"  height= \"50%\" />\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<img src=\"images/building_the_linear_system.png\" width= \"50%\"  height= \"50%\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Install the python packages:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge opencv\n",
    "pip install graphslam\n",
    "conda install conda-forge::gtsam\n",
    "conda install conda-forge::matplotlib\n",
    "conda install conda-forge::plotly\n",
    "```\n",
    "\n",
    "git submodule update --init\n",
    "\n",
    "\n",
    "\n",
    "To create a symlink at `destination` which references the original file `<original-ref>`, use:\n",
    "\n",
    "ln -s <original-ref> <destination>\n",
    "\n",
    "\n",
    "ln -s ~/workspace/robotic_notes/scripts ~/anaconda3/envs/robotic_notes/\n",
    "\n",
    "\n",
    "\n",
    "Refs: [1](https://python-graphslam.readthedocs.io/en/stable/), [2](https://github.com/goldbattle/simple_2d_slam)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "download g2o examples from [here](https://lucacarlone.mit.edu/datasets/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
