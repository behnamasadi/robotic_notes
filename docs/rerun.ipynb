{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e4d9e9-bfa0-45ec-9c41-3ce70e0c60de",
   "metadata": {},
   "source": [
    "# Basic concepts\n",
    "\n",
    "### Entity path\n",
    "\n",
    "```text\n",
    "\"world/points\"\n",
    "\"camera/image\"\n",
    "\"camera/rays\"\n",
    "```\n",
    "\n",
    "Like ROS topics, but hierarchical.\n",
    "\n",
    "# Time\n",
    "\n",
    "You explicitly set time:\n",
    "\n",
    "```python\n",
    "rr.set_time(\"video_frame\", sequence=frame_idx)\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```cpp\n",
    "rr::set_time(\"video_frame\", frame_idx);\n",
    "```\n",
    "\n",
    "Without time, everything is static.\n",
    "\n",
    "---\n",
    "\n",
    "# Logging Images\n",
    "\n",
    "\n",
    "```python\n",
    "import rerun as rr\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "rr.init(\"image_demo\", spawn=True)\n",
    "\n",
    "img = cv2.imread(\"image.png\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rr.log(\"camera/image\", rr.Image(img))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```cpp\n",
    "#include <rerun.hpp>\n",
    "#include <opencv2/opencv.hpp>\n",
    "\n",
    "cv::Mat img = cv::imread(\"image.png\");\n",
    "cv::cvtColor(img, img, cv::COLOR_BGR2RGB);\n",
    "\n",
    "rerun::log(\n",
    "    \"camera/image\",\n",
    "    rerun::Image(img.data, {img.cols, img.rows}, rerun::ColorModel::RGB)\n",
    ");\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#  Video (image sequence over time)\n",
    "\n",
    "### Key idea:\n",
    "\n",
    "**Video = images + time**\n",
    "\n",
    "\n",
    "```python\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "frame_idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    rr.set_time(\"frame\", frame_idx)\n",
    "    rr.log(\"camera/image\", rr.Image(frame))\n",
    "\n",
    "    frame_idx += 1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```cpp\n",
    "cv::VideoCapture cap(\"video.mp4\");\n",
    "int frame_idx = 0;\n",
    "\n",
    "cv::Mat frame;\n",
    "while (cap.read(frame)) {\n",
    "    cv::cvtColor(frame, frame, cv::COLOR_BGR2RGB);\n",
    "\n",
    "    rerun::set_time_sequence(\"frame\", frame_idx);\n",
    "\n",
    "    rerun::log(\n",
    "        \"camera/image\",\n",
    "        rerun::Image(frame.data, {frame.cols, frame.rows})\n",
    "    );\n",
    "\n",
    "    frame_idx++;\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#  2D & 3D Points\n",
    "\n",
    "## 2D keypoints\n",
    "\n",
    "```python\n",
    "pts = np.array([[100, 50], [120, 80], [200, 90]])\n",
    "\n",
    "rr.log(\n",
    "    \"image/keypoints\",\n",
    "    rr.Points2D(pts, radii=3)\n",
    ")\n",
    "```\n",
    "\n",
    "## 3D point cloud\n",
    "\n",
    "```python\n",
    "points = np.random.randn(1000, 3)\n",
    "\n",
    "rr.log(\n",
    "    \"world/points\",\n",
    "    rr.Points3D(points)\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```cpp\n",
    "std::vector<rerun::Vec3D> points;\n",
    "for (int i = 0; i < 1000; ++i) {\n",
    "    points.emplace_back(randf(), randf(), randf());\n",
    "}\n",
    "\n",
    "rerun::log(\"world/points\", rerun::Points3D(points));\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#  Shapes (Lines, Boxes, Arrows)\n",
    "\n",
    "## Line strip (trajectory)\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "trajectory = np.cumsum(np.random.randn(100, 3) * 0.1, axis=0)\n",
    "\n",
    "rr.log(\n",
    "    \"world/trajectory\",\n",
    "    rr.LineStrips3D([trajectory])\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```cpp\n",
    "std::vector<rerun::Vec3D> traj;\n",
    "...\n",
    "rerun::log(\n",
    "    \"world/trajectory\",\n",
    "    rerun::LineStrips3D({traj})\n",
    ");\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Boxes\n",
    "\n",
    "```python\n",
    "rr.log(\n",
    "    \"world/box\",\n",
    "    rr.Boxes3D(\n",
    "        centers=[[0,0,0]],\n",
    "        sizes=[[1,1,1]]\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#  Camera\n",
    "\n",
    "Rerun treats cameras **explicitly**\n",
    "\n",
    "---\n",
    "\n",
    "## Camera intrinsics\n",
    "\n",
    "\n",
    "```python\n",
    "rr.log(\n",
    "    \"world/camera\",\n",
    "    rr.Pinhole(\n",
    "        resolution=[640, 480],\n",
    "        focal_length=[500, 500],\n",
    "        principal_point=[320, 240]\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```cpp\n",
    "rerun::log(\n",
    "    \"world/camera\",\n",
    "    rerun::Pinhole(\n",
    "        {640, 480},\n",
    "        {500.0f, 500.0f},\n",
    "        {320.0f, 240.0f}\n",
    "    )\n",
    ");\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Camera pose (extrinsics)\n",
    "\n",
    "Camera pose = transform in world.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "rr.log(\n",
    "    \"world/camera\",\n",
    "    rr.Transform3D(\n",
    "        translation=[0, 0, 1],\n",
    "        rotation=rr.Quaternion(xyzw=[0,0,0,1])\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```cpp\n",
    "rerun::log(\n",
    "    \"world/camera\",\n",
    "    rerun::Transform3D(\n",
    "        rerun::Vec3D{0,0,1},\n",
    "        rerun::Quaternion{0,0,0,1}\n",
    "    )\n",
    ");\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Camera rays \n",
    "\n",
    "* **hovering pixel → ray**\n",
    "* requires:\n",
    "\n",
    "  * image\n",
    "  * pinhole\n",
    "  * transform\n",
    "\n",
    "If you log **image + pinhole + transform** under `\"world/camera\"`, Rerun automatically enables:\n",
    "\n",
    "* pixel hover\n",
    "* ray visualization\n",
    "* projection into 3D\n",
    "---\n",
    "\n",
    "\n",
    "```python\n",
    "import rerun as rr\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "rr.init(\"image_demo\", spawn=True)\n",
    "\n",
    "rr.log(\"world\", rr.ViewCoordinates.RIGHT_HAND_Z_UP, static=True)\n",
    "\n",
    "rr.log(\n",
    "    \"world/axes\",\n",
    "    rr.Arrows3D(\n",
    "        vectors=[[1, 0, 0], [0, 1, 0], [0, 0, 1]],\n",
    "        colors=[[255, 0, 0], [0, 255, 0], [0, 0, 255]],\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "rr.log(\n",
    "    \"world/camera\",\n",
    "    rr.Pinhole(\n",
    "        resolution=[640, 480],\n",
    "        focal_length=[500, 500],\n",
    "        principal_point=[320, 240]\n",
    "    )\n",
    ")\n",
    "\n",
    "rr.log(\n",
    "    \"world/camera\",\n",
    "    rr.Transform3D(\n",
    "        translation=[0, 0, 1],\n",
    "        rotation=rr.Quaternion(xyzw=[0, 0, 0, 1])\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "img = cv2.imread(\"iamge.png\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rr.log(\"world/camera\", rr.Image(img))\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab510490-edf7-4174-99ed-bb13c4c1edf7",
   "metadata": {},
   "source": [
    "# Rerun View Coordinates\n",
    "\n",
    "`rr.ViewCoordinates` is an archetype you log to define the **semantic meaning** of the X, Y, and Z axes.\n",
    "This tells the Rerun Viewer how to interpret your coordinate system, which affects.\n",
    "\n",
    "It does **not** transform or flip your actual point positions — it only influences how the viewer orients the scene for better usability.\n",
    "\n",
    "### Specific Constants\n",
    "\n",
    "**Rerun** Default\n",
    "- **`rr.ViewCoordinates.RIGHT_HAND_Z_UP`**  \n",
    "  Defines the axes as: **X = Right**, **Y = Forward**, **Z = Up**\n",
    "\n",
    "\n",
    "\n",
    "**OpenCV** (RDF: Right-Down-Forward) convention:\n",
    "- **`rr.ViewCoordinates.RIGHT_HAND_Y_DOWN`**  \n",
    "  Defines the axes as: **X = Right**, **Y = Down**, **Z = Forward**  \n",
    "  \n",
    "```python\n",
    "rr.log(\"world\", rr.ViewCoordinates.RIGHT_HAND_Y_DOWN, static=True)\n",
    "\n",
    "rr.log(\"world/points\",\n",
    "       rr.Points3D([[0, 0, 0], [1, 0, 0], [0, 0, 4]], radii=0.2))\n",
    "\n",
    "\n",
    "rr.log(\n",
    "    \"world/axes\",\n",
    "    rr.Arrows3D(\n",
    "        vectors=[[1, 0, 0], [0, 1, 0], [0, 0, 1]],\n",
    "        colors=[[255, 0, 0], [0, 255, 0], [0, 0, 255]],\n",
    "    ),\n",
    ")\n",
    "\n",
    "```\n",
    "<img src=\"images/rerun_RDF_opencv_coordinate.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7b74c-e917-43a1-b86c-48a873515fe0",
   "metadata": {},
   "source": [
    "# OpenCV Images in Rerun\n",
    "\n",
    "\n",
    "Rerun world:\n",
    "\n",
    "```\n",
    "X → right\n",
    "Y → forward\n",
    "Z → up\n",
    "```\n",
    "\n",
    "OpenCV:\n",
    "\n",
    "```\n",
    "X → right\n",
    "Y → down\n",
    "Z → forward\n",
    "```\n",
    "\n",
    "### Position\n",
    "\n",
    "```\n",
    "X_rerun =  X_cv\n",
    "Y_rerun =  Z_cv\n",
    "Z_rerun = -Y_cv\n",
    "```\n",
    "\n",
    "### Rotation\n",
    "\n",
    "$$\n",
    "R_{\\text{rerun}\\leftarrow\\text{cv}} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0  \\\\\n",
    "0 & 0 & 1  \\\\\n",
    "0 & -1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For integrating OpenCV camera data with Rerun when you want a **Z-up world** (common in robotics, AR, etc.).\n",
    "\n",
    "```python\n",
    "points_cv = np.array([\n",
    "    [0.0,  0.0, 2.0],   # straight ahead\n",
    "    [0.5,  0.0, 2.0],   # right\n",
    "    [-0.5, 0.0, 2.0],   # left\n",
    "    [0.0,  0.5, 2.0],   # down\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# Convert OpenCV → Rerun world\n",
    "# World: X=right, Y=forward, Z=up\n",
    "# ============================================================\n",
    "points_world = np.column_stack([\n",
    "    points_cv[:, 0],    # X stays X\n",
    "    points_cv[:, 2],    # Z (forward) → Y\n",
    "    -points_cv[:, 1],   # -Y (down) → Z (up)\n",
    "])\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Should you instead \"just choose Z down\" (e.g., make world Y-down)?\n",
    "No — only if you specifically want a Y-down world (e.g., matching some simulations or datasets). But:\n",
    "- It would require **no point transformation** (you could log points_cv directly).\n",
    "- You'd change the world to something like `rr.ViewCoordinates.RIGHT_HAND_Y_DOWN` (X right, Y down, Z forward).\n",
    "- The camera pose could be identity (camera forward = +Z_world).\n",
    "- However, you'd lose the natural \"Z up\" viewing experience in Rerun's 3D viewer for ground-plane robotics/AR scenarios.\n",
    "\n",
    "Your current approach (transform points + pose, keep Z-up world) is more common and flexible when working with real-world upward gravity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862d86c-1eec-410a-88d3-2b13dabefac5",
   "metadata": {},
   "source": [
    "# How to Animate Objects in Rerun\n",
    "\n",
    "Animating objects (like a camera, robot, or points) in a Rerun scene is simple and powerful thanks to its timeline-based logging.\n",
    "\n",
    "The key idea: **log the same entity path at different times** with updated transforms or data.\n",
    "\n",
    "\n",
    "1. **Set a timeline** for each frame:  \n",
    "   Use `rr.set_time(\"frame\", frame_idx)`  before logging data in a loop.\n",
    "\n",
    "2. **Log time-varying data** to the same entity path:  \n",
    "   For a moving object (e.g., a camera), repeatedly log a `rr.Transform3D` with new translation/rotation:\n",
    "   ```python\n",
    "   rr.log(\"world/camera\", rr.Transform3D(\n",
    "       translation=[x, y, z],\n",
    "       rotation=rr.Quaternion(xyzw=[qx, qy, qz, qw])\n",
    "   ))\n",
    "   ```\n",
    "\n",
    "3. **Log associated data** (images, points, etc.) at the same timestamp:  \n",
    "   They will automatically synchronize with the transform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74635475-152c-4d03-8b26-4ac22818e6bd",
   "metadata": {},
   "source": [
    "```python\n",
    "import rerun.blueprint as rrb\n",
    "import rerun as rr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "rr.init(\"rerun_demo\", spawn=True)\n",
    "rr.log(\"world/xyz\", rr.Arrows3D(vectors=[[1, 0, 0], [0, 1, 0],\n",
    "       [0, 0, 1]], colors=[[255, 0, 0], [0, 255, 0], [0, 0, 255]],),)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Setup Camera and Webcam\n",
    "# ============================================================================\n",
    "resolution = [1280, 720]\n",
    "fx = 848.53117539872062\n",
    "fy = 848.53117539872062\n",
    "cx = 639.5\n",
    "cy = 359.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set camera resolution to 1280x720\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, resolution[0])\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, resolution[1])\n",
    "\n",
    "# Open a video file (alternative)\n",
    "# cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "entity_path = \"world/camera\"\n",
    "\n",
    "# Log camera intrinsics (static - only once)\n",
    "rr.log(\n",
    "    entity_path,\n",
    "    rr.Pinhole(\n",
    "        resolution=[resolution[0], resolution[1]],\n",
    "        focal_length=[fx, fy],\n",
    "        principal_point=[cx, cy],\n",
    "        # Distance from camera origin to image plane for 3D visualization\n",
    "        image_plane_distance=1.0,\n",
    "        color=[255, 128, 0],  # Orange color for camera frustum\n",
    "        line_width=0.003  # Width of camera frustum lines\n",
    "    ),\n",
    "    static=True  # Camera intrinsics are static\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Live webcam feed with animated camera position\n",
    "# ============================================================================\n",
    "num_frames = 90  # Number of frames to capture\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    # Set time for this frame\n",
    "    rr.set_time(\"frame\", sequence=frame_idx)\n",
    "\n",
    "    # Read webcam frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read frame from webcam\")\n",
    "        break\n",
    "\n",
    "    # Convert BGR to RGB for Rerun\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Log image to camera (this will display in camera view)\n",
    "    rr.log(entity_path, rr.Image(img_rgb))\n",
    "\n",
    "    # Update camera position (animate in world)\n",
    "    # Move camera along X-axis over time\n",
    "    translation = [0.02 * frame_idx, 0, 1]\n",
    "    rr.log(\n",
    "        entity_path,\n",
    "        rr.Transform3D(\n",
    "            translation=translation,\n",
    "            rotation=rr.Quaternion(xyzw=[0, 0, 0, 1])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Small delay to allow Rerun to process and control frame rate\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Release webcam\n",
    "cap.release()\n",
    "print(f\"Captured {num_frames} frames\")\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
