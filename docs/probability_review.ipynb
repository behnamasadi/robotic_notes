{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d59085-f3b3-41fc-9110-2e0d3f3f2315",
   "metadata": {},
   "source": [
    "### A) Conditioning on **parameters** (statistics / ML)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(\\text{data} \\mid \\mu, \\Sigma)\n",
    "}\n",
    "$$\n",
    "\n",
    "Meaning:\n",
    "\n",
    "* ‚ÄúThe probability of the data **given fixed parameters**‚Äù\n",
    "* $\\mu,\\Sigma$ are **not random**\n",
    "* This is a **likelihood function**\n",
    "\n",
    "You are asking:\n",
    "\n",
    "> ‚ÄúIf the distribution were $\\mathcal{N}(\\mu,\\Sigma)$, how likely is the data?‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### B) Conditioning on **random variables** (probability / Bayes)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(x \\mid y)\n",
    "}\n",
    "$$\n",
    "\n",
    "Meaning:\n",
    "\n",
    "* $x$ and $y$ are **both random variables**\n",
    "* $y$ is observed\n",
    "* $x$ is uncertain\n",
    "* Result is a **new distribution over $x$**\n",
    "\n",
    "This is **inference**, not parameter fitting.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Why both notations are correct\n",
    "\n",
    "They answer **different questions**.\n",
    "\n",
    "| Expression                | Question it answers                                       |\n",
    "| ------------------------- | --------------------------------------------------------- |\n",
    "| $p(data \\mid \\mu,\\Sigma)$ | ‚ÄúHow likely is this data under these parameters?‚Äù         |\n",
    "| $p(x \\mid y)$             | ‚ÄúGiven that I observed $y$, what do I believe about $x$?‚Äù |\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ What is $\\mu,\\Sigma$ in $p(x \\mid y)$ then?\n",
    "\n",
    "They are **hidden inside the joint distribution**.\n",
    "\n",
    "You start with:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mu_x \\\\\n",
    "\\mu_y\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "\\Sigma_{xx} & \\Sigma_{xy} \\\\\n",
    "\\Sigma_{yx} & \\Sigma_{yy}\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$p(x \\mid y)=\\frac{p(x,y)}{p(y)}$$\n",
    "\n",
    "The parameters are **still there**, just implicit.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Concrete example (anchors intuition)\n",
    "\n",
    "### Case 1 ‚Äî Likelihood of data\n",
    "\n",
    "You model sensor noise:\n",
    "\n",
    "$$\n",
    "z \\sim \\mathcal{N}(h(x), \\Sigma)\n",
    "$$\n",
    "\n",
    "You evaluate:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(z \\mid x)\n",
    "}\n",
    "$$\n",
    "\n",
    "This is a **likelihood**, used for optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### Case 2 ‚Äî Inference of a hidden variable\n",
    "\n",
    "You model joint uncertainty:\n",
    "\n",
    "$$\n",
    "(x, y) \\sim \\mathcal{N}(\\mu, \\Sigma)\n",
    "$$\n",
    "\n",
    "You observe $y=y_0$ and compute:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(x \\mid y=y_0)\n",
    "}\n",
    "$$\n",
    "\n",
    "This is **posterior inference**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Why this matters in SLAM / Kalman filtering\n",
    "\n",
    "In Kalman filtering:\n",
    "\n",
    "* State: $x$\n",
    "* Measurement: $z$\n",
    "\n",
    "You write:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(z \\mid x)\n",
    "}\n",
    "$$\n",
    "\n",
    "But when you update the belief, you compute:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(x \\mid z)\n",
    "}\n",
    "$$\n",
    "\n",
    "Same ingredients ‚Äî **different direction**.\n",
    "\n",
    "Bayes rule connects them:\n",
    "\n",
    "$$\\boxed{p(x \\mid z)=\\frac{p(z \\mid x)p(x)}{p(z)}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Why your intuition feels conflicted\n",
    "\n",
    "Because textbooks often **mix languages**:\n",
    "\n",
    "* ML books talk about **likelihood**\n",
    "* Probability books talk about **conditional distributions**\n",
    "* Robotics mixes both constantly\n",
    "\n",
    "But the rule is simple:\n",
    "\n",
    "> **Parameters are fixed. Variables are random.**\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Final mental model (lock this in)\n",
    "\n",
    "### Think in terms of roles:\n",
    "\n",
    "| Symbol                    | Role                     |\n",
    "| ------------------------- | ------------------------ |\n",
    "| $x,y,z$                   | Random variables         |\n",
    "| $\\mu,\\Sigma$              | Model parameters         |\n",
    "| $p(data \\mid \\mu,\\Sigma)$ | Likelihood               |\n",
    "| $p(x \\mid y)$             | Conditional distribution |\n",
    "| $p(x \\mid z)$             | Posterior                |\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ One sentence summary (important)\n",
    "\n",
    "> $p(data \\mid \\mu,\\Sigma)$ scores data under a model,\n",
    "> $p(x \\mid y)$ **changes your belief** about one variable after observing another.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17626e0b-5952-4537-bd81-25123c747f2a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ One formula, two interpretations\n",
    "\n",
    "Start with the Gaussian density:\n",
    "\n",
    "$$\n",
    "p(x \\mid \\mu, \\Sigma) = \n",
    "\\frac{1}{\\sqrt{(2\\pi)^d \\det\\Sigma}}\n",
    "\\exp\\left(\n",
    "-\\frac{1}{2}\n",
    "(x-\\mu)^\\top \\Sigma^{-1} (x-\\mu)\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This expression **never changes**.\n",
    "\n",
    "What changes is:\n",
    "\n",
    "* **what is fixed**\n",
    "* **what is unknown**\n",
    "* **what question you are asking**\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Probability (predictive view)\n",
    "\n",
    "### Question being asked\n",
    "\n",
    "> ‚ÄúIf the parameters are known, how likely is a value?‚Äù\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "* $\\mu,\\Sigma$ are **fixed**\n",
    "* $x$ is **random**\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\text{Probability view: } p(x \\mid \\mu,\\Sigma)\n",
    "}\n",
    "$$\n",
    "\n",
    "You integrate over $x$:\n",
    "\n",
    "$$\n",
    "\\int p(x \\mid \\mu,\\Sigma),dx = 1\n",
    "$$\n",
    "\n",
    "This is a **true probability distribution**.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Likelihood (inverse view)\n",
    "\n",
    "### Question being asked\n",
    "\n",
    "> ‚ÄúGiven observed data, which parameters explain it best?‚Äù\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "* $x$ is **fixed (observed)**\n",
    "* $\\mu,\\Sigma$ are **unknown**\n",
    "\n",
    "You *reuse the same formula* but reinterpret it as:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathcal{L}(\\mu,\\Sigma \\mid x)\n",
    "\\triangleq\n",
    "p(x \\mid \\mu,\\Sigma)\n",
    "}\n",
    "$$\n",
    "\n",
    "Now:\n",
    "\n",
    "* This is **not a probability distribution**\n",
    "* It does **not integrate to 1 over $\\mu,\\Sigma$**\n",
    "* It is a **score function**\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ This is the key mental switch\n",
    "\n",
    "> **Probability asks about data given parameters**\n",
    "> **Likelihood asks about parameters given data**\n",
    "\n",
    "Same formula. Different roles.\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Why likelihood is not a probability\n",
    "\n",
    "Take a fixed observation $x_0$.\n",
    "\n",
    "As a function of $\\mu$:\n",
    "\n",
    "$$\\mathcal{L}(\\mu \\mid x_0)=p(x_0 \\mid \\mu) $$\n",
    "\n",
    "This:\n",
    "\n",
    "* does **not** integrate to 1 over $\\mu$\n",
    "* can be larger than 1\n",
    "* is only meaningful **up to proportionality**\n",
    "\n",
    "That is why we maximize likelihood instead of integrating it.\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Bayesian view: where probability of parameters appears\n",
    "\n",
    "If you want a **probability distribution over parameters**, you must add a prior:\n",
    "\n",
    "$$\\boxed{p(\\mu \\mid x)=\\frac{p(x \\mid \\mu),p(\\mu)}{p(x)}}\n",
    "$$\n",
    "\n",
    "Now:\n",
    "\n",
    "* $p(\\mu \\mid x)$ **is** a probability\n",
    "* integrates to 1\n",
    "* combines **likelihood + prior**\n",
    "\n",
    "This is Bayesian inference.\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ How this relates to $p(x \\mid y)$\n",
    "\n",
    "In:\n",
    "\n",
    "$$\n",
    "p(x \\mid y)\n",
    "$$\n",
    "\n",
    "* $x$ and $y$ are **both random variables**\n",
    "* this is **always a probability**\n",
    "* no parameters are being optimized\n",
    "\n",
    "So:\n",
    "\n",
    "| Expression                       | What it is                  |\n",
    "| -------------------------------- | --------------------------- |\n",
    "| $p(x \\mid \\mu,\\Sigma)$           | Probability *or* likelihood |\n",
    "| $\\mathcal{L}(\\mu,\\Sigma \\mid x)$ | Likelihood                  |\n",
    "| $p(x \\mid y)$                    | Conditional probability     |\n",
    "| $p(\\mu \\mid x)$                  | Posterior probability       |\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ Why SLAM and least squares use likelihood\n",
    "\n",
    "In SLAM:\n",
    "\n",
    "$$\n",
    "z = h(x) + \\epsilon,\\quad \\epsilon \\sim \\mathcal{N}(0,\\Sigma)\n",
    "$$\n",
    "\n",
    "You write:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(z \\mid x)\n",
    "}\n",
    "$$\n",
    "\n",
    "This is a **likelihood in $x$**, not a probability in $x$.\n",
    "\n",
    "Taking log:\n",
    "\n",
    "$$\\log p(z \\mid x)=-\\frac{1}{2}\\boxed{$r^\\top \\Sigma^{-1} r$}* \\text{const}  $$\n",
    "\n",
    "That boxed term becomes your least-squares cost.\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ One-sentence rule (lock this in)\n",
    "\n",
    "> **If the variable integrates to 1 ‚Üí probability**\n",
    "> **If you optimize it ‚Üí likelihood**\n",
    "\n",
    "---\n",
    "\n",
    "## üîü Final intuition (very important)\n",
    "\n",
    "You are **not changing mathematics**\n",
    "You are **changing perspective**\n",
    "\n",
    "Same formula.\n",
    "Different question.\n",
    "\n",
    "Once this clicks, MAP, Kalman filters, SLAM, and factor graphs all become much easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ed494-1cb8-4082-a4aa-f583e47bb033",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Probability density**: vary $x$, fix $\\mu,\\sigma$\n",
    "2. **Likelihood**: fix observed $x_0$, vary $\\mu$ (treat $\\mu$ as variable)\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Your Gaussian function (slightly cleaned)\n",
    "\n",
    "We‚Äôll keep your function and add the normalization so it is a true PDF:\n",
    "\n",
    "$$\n",
    "\\boxed{p(x \\mid \\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7437c4-73a1-4751-b8ed-37085419f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gaussian(x, mu, sig):\n",
    "    return (1.0 / (np.sqrt(2 * np.pi) * sig)) * \\\n",
    "           np.exp(-0.5 * ((x - mu) / sig)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479cb196-5323-4340-b7e0-4d54940a0e28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Probability density plot (x is random)\n",
    "\n",
    "Here:\n",
    "\n",
    "* $\\mu,\\sigma$ are fixed\n",
    "* $x$ varies\n",
    "* This **integrates to 1**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff02fe8b-4926-4e1d-a9f1-2428c735926b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-6, 6, 1000)\n",
    "mu = 1.0\n",
    "sig = 1.2\n",
    "\n",
    "p_x = gaussian(x, mu, sig)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(x, p_x, linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"p(x | Œº, œÉ)\")\n",
    "plt.title(\"Probability Density Function\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1eb5ec-21c9-4ea1-93e5-755e7c55136d",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "This answers:\n",
    "\n",
    "> ‚ÄúIf the parameters are $\\mu=1,\\sigma=1.2$, how likely are different values of $x$?‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Likelihood plot (Œº is variable)\n",
    "\n",
    "Now we **freeze the observed data point**:\n",
    "\n",
    "$$\n",
    "x_0 = 2.0\n",
    "$$\n",
    "\n",
    "and vary $\\mu$.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$\\boxed{\\mathcal{L}(\\mu \\mid x_0)=p(x_0 \\mid \\mu,\\sigma)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2efe5f-6eda-414b-b722-f9a0540500f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_vals = np.linspace(-6, 6, 1000)\n",
    "x0 = 2.0\n",
    "sig = 1.2\n",
    "\n",
    "likelihood = gaussian(x0, mu_vals, sig)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(mu_vals, likelihood, linewidth=2)\n",
    "plt.xlabel(\"Œº\")\n",
    "plt.ylabel(\"L(Œº | x‚ÇÄ)\")\n",
    "plt.title(\"Likelihood Function\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89a271-1543-489a-870c-19c6af33e53c",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "This answers:\n",
    "\n",
    "> ‚ÄúGiven that I observed $x_0=2$, which $\\mu$ explains it best?‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Critical observation (this is the punchline)\n",
    "\n",
    "* **The curves look identical**\n",
    "* **The math is identical**\n",
    "* **The meaning is completely different**\n",
    "\n",
    "| Plot        | Variable | Fixed        | Meaning                |\n",
    "| ----------- | -------- | ------------ | ---------------------- |\n",
    "| Probability | $x$      | $\\mu,\\sigma$ | Distribution over data |\n",
    "| Likelihood  | $\\mu$    | $x_0,\\sigma$ | Score over parameters  |\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Why likelihood is not a probability\n",
    "\n",
    "Try integrating the likelihood over $\\mu$:\n",
    "\n",
    "```python\n",
    "np.trapz(likelihood, mu_vals)\n",
    "```\n",
    "\n",
    "It will **not equal 1**.\n",
    "\n",
    "That‚Äôs why likelihood:\n",
    "\n",
    "* is not a probability\n",
    "* is maximized, not integrated\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ One-line mental rule (lock this in)\n",
    "\n",
    "> **Same formula, different question**\n",
    "> **Probability varies data**\n",
    "> **Likelihood varies parameters**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3d97b-b0a8-4263-8f49-c04975d5177b",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Likelihood does **not** mean \"only $\\mu$ is variable\"\n",
    "\n",
    "The definition of likelihood is:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathcal{L}(\\theta \\mid x_0) \\triangleq p(x_0 \\mid \\theta)\n",
    "}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $x_0$ is **observed data** (fixed)\n",
    "* $\\theta$ is **the set of unknown parameters**\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ In a 1D Gaussian, the parameters are\n",
    "\n",
    "$$\n",
    "\\theta = \\{\\mu,\\sigma\\}\n",
    "$$\n",
    "\n",
    "So the **full likelihood** is actually:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathcal{L}(\\mu,\\sigma \\mid x_0) = p(x_0 \\mid \\mu,\\sigma)\n",
    "}\n",
    "$$\n",
    "\n",
    "Nothing is missing.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Why we *often* write $\\mathcal{L}(\\mu \\mid x_0)$\n",
    "\n",
    "This is a **choice**, not a rule.\n",
    "\n",
    "In your plot example, we **decided** to:\n",
    "\n",
    "* treat $\\sigma$ as known\n",
    "* estimate only $\\mu$\n",
    "\n",
    "So we implicitly fixed $\\sigma$ and wrote:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathcal{L}(\\mu \\mid x_0) = p(x_0 \\mid \\mu,\\sigma_{\\text{fixed}})\n",
    "}\n",
    "$$\n",
    "\n",
    "That's why $\\sigma$ does not appear as a variable.\n",
    "\n",
    "> Likelihood notation usually hides fixed parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ You could just as well estimate $\\sigma$\n",
    "\n",
    "If $\\mu$ is fixed and $\\sigma$ is unknown:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathcal{L}(\\sigma \\mid x_0) = p(x_0 \\mid \\mu,\\sigma)\n",
    "}\n",
    "$$\n",
    "\n",
    "Now **$\\sigma$ is the variable**.\n",
    "\n",
    "Or both:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathcal{L}(\\mu,\\sigma \\mid x_0) = p(x_0 \\mid \\mu,\\sigma)\n",
    "}\n",
    "$$\n",
    "\n",
    "This is a **2D likelihood surface**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Why textbooks often focus on $\\mu$\n",
    "\n",
    "Three practical reasons:\n",
    "\n",
    "### ‚ë† Pedagogy\n",
    "\n",
    "* 1D curve is easy to visualize\n",
    "* 2D likelihood surfaces are harder\n",
    "\n",
    "### ‚ë° Common assumptions\n",
    "\n",
    "* Noise level $\\sigma$ often comes from sensor specs\n",
    "* Engineers fix $\\sigma$ and estimate $\\mu$\n",
    "\n",
    "### ‚ë¢ Optimization convenience\n",
    "\n",
    "* Many estimators assume known covariance\n",
    "* This leads directly to least squares\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Important distinction (this is key)\n",
    "\n",
    "| Role                               | Fixed        | Variable     |\n",
    "| ---------------------------------- | ------------ | ------------ |\n",
    "| Probability $p(x \\mid \\mu,\\sigma)$  | $\\mu,\\sigma$ | $x$          |\n",
    "| Likelihood $\\mathcal{L}(\\mu,\\sigma \\mid x_0)$ | $x_0$        | $\\mu,\\sigma$ |\n",
    "| Your example                       | $x_0,\\sigma$ | $\\mu$        |\n",
    "\n",
    "So **$\\sigma$ is not \"missing\"** ‚Äî it's **conditioned on**.\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ One-sentence rule (lock this in)\n",
    "\n",
    "> **Likelihood varies the unknowns, not the data**\n",
    "\n",
    "Whatever you are trying to estimate becomes the variable of the likelihood.\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ SLAM / robotics connection (important)\n",
    "\n",
    "In SLAM we usually write:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(z \\mid x,\\Sigma)\n",
    "}\n",
    "$$\n",
    "\n",
    "and treat:\n",
    "\n",
    "* $z$ fixed $=$ measurement\n",
    "* $x$ variable $=$ state\n",
    "* $\\Sigma$ fixed $=$ noise model\n",
    "\n",
    "That is **exactly the same pattern**.\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ Final clarity check\n",
    "\n",
    "‚ùå Likelihood variable is always $\\mu$\n",
    "‚úÖ Likelihood variable is **whatever parameter is unknown**\n",
    "‚úÖ $\\sigma$ disappears only because **you fixed it**\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229433b-1879-44cb-bd02-39a2dbc7f409",
   "metadata": {},
   "source": [
    "## Mean and Covariance of a Conditional Gaussian\n",
    "\n",
    "---\n",
    "\n",
    "## Setup (joint Gaussian)\n",
    "\n",
    "Assume a **joint Gaussian** over two random vectors $x$ and $y$:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mu_x \\\\\n",
    "\\mu_y\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "\\Sigma_{xx} & \\Sigma_{xy} \\\\\n",
    "\\Sigma_{yx} & \\Sigma_{yy}\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "* $x \\in \\mathbb{R}^n$\n",
    "* $y \\in \\mathbb{R}^m$\n",
    "\n",
    "---\n",
    "\n",
    "## Conditional distribution $p(x \\mid y)$\n",
    "\n",
    "The conditional is **still Gaussian**:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(x \\mid y) = \\mathcal{N}\\left(\\mu_{x\\mid y}, \\Sigma_{x\\mid y}\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conditional mean (this is what you asked for)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mu_{x\\mid y} = \\mu_x + \\Sigma_{xy}\\Sigma_{yy}^{-1}(y - \\mu_y)\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conditional covariance (for completeness)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\Sigma_{x\\mid y} = \\Sigma_{xx} - \\Sigma_{xy}\\Sigma_{yy}^{-1}\\Sigma_{yx}\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Very important intuition (do not skip)\n",
    "\n",
    "### Mean update\n",
    "\n",
    "* Starts from the prior mean $\\mu_x$\n",
    "* Shifts **toward values consistent with $y$**\n",
    "* Shift direction and strength controlled by cross-covariance $\\Sigma_{xy}$\n",
    "\n",
    "This is **exactly a correction term**.\n",
    "\n",
    "---\n",
    "\n",
    "### Covariance update\n",
    "\n",
    "* Always **shrinks or stays the same**\n",
    "* Conditioning can **never increase uncertainty**\n",
    "* Reduction amount depends on how informative $y$ is\n",
    "\n",
    "---\n",
    "\n",
    "## Scalar special case (1D intuition)\n",
    "\n",
    "If $x,y$ are scalars:\n",
    "\n",
    "$$\n",
    "\\mu_{x\\mid y} = \\mu_x + \\frac{\\sigma_{xy}}{\\sigma_y^2}(y - \\mu_y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_{x\\mid y}^2 = \\sigma_x^2 - \\frac{\\sigma_{xy}^2}{\\sigma_y^2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Critical connection (Kalman filter)\n",
    "\n",
    "If you rename:\n",
    "\n",
    "* $\\Sigma_{xy}\\Sigma_{yy}^{-1}$ ‚Üí **Kalman gain**\n",
    "* $y - \\mu_y$ ‚Üí **innovation**\n",
    "\n",
    "then the mean equation becomes:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mu_{x\\mid y} = \\mu_x + K(y - \\mu_y)\n",
    "}\n",
    "$$\n",
    "\n",
    "This is why Kalman filtering is **just conditional Gaussians**.\n",
    "\n",
    "---\n",
    "\n",
    "## One-line takeaway (lock this in)\n",
    "\n",
    "> **Conditional mean = prior mean + covariance-weighted correction**\n",
    "> **Conditional covariance = prior covariance ‚àí explained uncertainty**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964779ed-d79b-46d8-9616-63ae10c4aaa2",
   "metadata": {},
   "source": [
    "## Example 1: Robot Localization\n",
    "\n",
    "\n",
    "Let's create a physical example in the context of robotics that illustrates the conditional distribution of one variable given another when they follow a joint Gaussian distribution.\n",
    "\n",
    "### Scenario: Robot Localization\n",
    "\n",
    "Imagine a robot navigating a two-dimensional space, equipped with a GPS sensor and a compass. The robot's state can be described by two variables:\n",
    "1. $ x $: The robot's position along the x-axis.\n",
    "2. $ y $: The robot's heading angle (orientation) measured by the compass.\n",
    "\n",
    "The robot's state vector is:\n",
    "$ \\mathbf{z} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} $\n",
    "\n",
    "Due to sensor noise and environmental factors, both $ x $ and $ y $ are random variables and are jointly Gaussian distributed.\n",
    "\n",
    "### Joint Gaussian Distribution\n",
    "\n",
    "Assume the robot's state follows this joint Gaussian distribution:\n",
    "$ \\mathbf{z} \\sim \\mathcal{N} \\left( \\begin{bmatrix} 5 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 2 & 0.5 \\\\ 0.5 & 1 \\end{bmatrix} \\right) $\n",
    "\n",
    "- Mean position ($ x $): 5 meters along the x-axis.\n",
    "- Mean heading ($ y $): 0 radians (pointing straight forward).\n",
    "- Variance in position: 2 $(\\text{meters}^2)$\n",
    "- Variance in heading: 1 $(\\text{radians}^2)$\n",
    "- Covariance between position and heading: 0.5\n",
    "\n",
    "### Problem\n",
    "\n",
    "Given a specific heading measurement, $ y = y_0 $, we want to find the conditional distribution of the robot's position $ x $.\n",
    "\n",
    "### Conditional Distribution Calculation\n",
    "\n",
    "#### 1. Extract Parameters\n",
    "\n",
    "From the joint distribution:\n",
    "$ \\mathbf{\\mu_z} = \\begin{bmatrix} 5 \\\\ 0 \\end{bmatrix} $\n",
    "$ \\mathbf{\\Sigma_z} = \\begin{bmatrix} 2 & 0.5 \\\\ 0.5 & 1 \\end{bmatrix} $\n",
    "\n",
    "#### 2. Conditional Mean\n",
    "\n",
    "The conditional mean of $ x $ given $ y = y_0 $:\n",
    "$ \\mu_{x|y} = \\mu_x + \\Sigma_{xy} \\Sigma_{yy}^{-1} (y_0 - \\mu_y) $\n",
    "\n",
    "Plugging in the values:\n",
    "- $\\mu_x = 5$\n",
    "- $\\mu_y = 0$\n",
    "- $\\Sigma_{xy} = 0.5$\n",
    "- $\\Sigma_{yy} = 1$\n",
    "\n",
    "$ \\mu_{x|y} = 5 + 0.5 \\cdot 1^{-1} (y_0 - 0) = 5 + 0.5 \\cdot y_0 $\n",
    "\n",
    "#### 3. Conditional Covariance\n",
    "\n",
    "The conditional covariance of $ x $ given $ y $:\n",
    "$ \\Sigma_{x|y} = \\Sigma_{xx} - \\Sigma_{xy} \\Sigma_{yy}^{-1} \\Sigma_{yx} $\n",
    "\n",
    "Plugging in the values:\n",
    "- $\\Sigma_{xx} = 2$\n",
    "- $\\Sigma_{xy} = 0.5$\n",
    "- $\\Sigma_{yy} = 1$\n",
    "\n",
    "$ \\Sigma_{x|y} = 2 - 0.5 \\cdot 1^{-1} \\cdot 0.5 = 2 - 0.25 = 1.75 $\n",
    "\n",
    "### Conditional Distribution\n",
    "\n",
    "Given $ y = y_0 $, the conditional distribution of $ x $ is:\n",
    "$ x | y = y_0 \\sim \\mathcal{N} \\left( 5 + 0.5 y_0, 1.75 \\right) $\n",
    "\n",
    "### Physical Interpretation\n",
    "\n",
    "1. **Prior Distribution:**\n",
    "   - Before any heading measurement, the robot's position $ x $ is normally distributed with mean 5 meters and variance 2 $(\\text{meters}^2)$.\n",
    "   - The heading $ y $ is normally distributed with mean 0 radians and variance 1 $(\\text{radians}^2)$.\n",
    "\n",
    "2. **Conditional Distribution:**\n",
    "   - Once the robot measures its heading $ y = y_0 $, it updates its belief about its position $ x $.\n",
    "   - The new mean position $ x $ is adjusted based on the measured heading $ y_0 $, specifically by the amount $ 0.5 y_0 $.\n",
    "   - The uncertainty (variance) about the position $ x $ is reduced to 1.75 $(\\text{meters}^2)$.\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "Suppose the robot measures its heading to be $ y_0 = 2 $ radians.\n",
    "\n",
    "1. **Conditional Mean:**\n",
    "   $ \\mu_{x|y} = 5 + 0.5 \\cdot 2 = 5 + 1 = 6 $\n",
    "\n",
    "2. **Conditional Covariance:**\n",
    "   $ \\Sigma_{x|y} = 1.75 $\n",
    "\n",
    "Given this heading measurement, the robot's updated belief about its position is:\n",
    "$ x | y = 2 \\sim \\mathcal{N} \\left( 6, 1.75 \\right) $\n",
    "\n",
    "This means the robot now believes it is centered around 6 meters along the x-axis, with a reduced uncertainty compared to before the heading measurement.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Joint Distribution:** $\\mathbf{z} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\sim \\mathcal{N} \\left( \\begin{bmatrix} 5 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 2 & 0.5 \\\\ 0.5 & 1 \\end{bmatrix} \\right)$\n",
    "- **Conditional Distribution (given $ y = 2 $):** $ x | y = 2 \\sim \\mathcal{N} \\left( 6, 1.75 \\right) $\n",
    "\n",
    "This example shows how a robot can use joint Gaussian properties to update its position estimate based on a heading measurement, reducing uncertainty in its localization process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86ad018-9497-4806-822b-d16b72105d7a",
   "metadata": {},
   "source": [
    "\n",
    "# 1Ô∏è‚É£ What you already did: conditional distribution (inference)\n",
    "\n",
    "You started from a **joint Gaussian belief**:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "5 \\\\\n",
    "0\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "2 & 0.5 \\\\\n",
    "0.5 & 1\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Then you asked:\n",
    "\n",
    "> \"If I **observe** $y = y_0$, what is my belief about $x$?\"\n",
    "\n",
    "That is:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(x \\mid y=y_0)\n",
    "}\n",
    "$$\n",
    "\n",
    "You correctly derived:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "x \\mid y=y_0 \\sim \\mathcal{N}\n",
    "\\left(\n",
    "5 + 0.5 \\cdot y_0,; 1.75\n",
    "\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "This is **Bayesian inference**:\n",
    "\n",
    "* $y$ is observed\n",
    "* $x$ is random\n",
    "* result is a **new probability distribution**\n",
    "\n",
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ Now change ONLY the question ‚Üí likelihood\n",
    "\n",
    "Let's keep **the same robot, the same physics**, but ask a *different question*.\n",
    "\n",
    "---\n",
    "\n",
    "## Likelihood question\n",
    "\n",
    "> \"Suppose the robot is at position $x$.\n",
    "> How likely is it that the compass would measure heading $y_0$?\"\n",
    "\n",
    "This is:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(y_0 \\mid x)\n",
    "}\n",
    "$$\n",
    "\n",
    "This is a **likelihood**, not a conditional belief.\n",
    "\n",
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ Extract likelihood from your joint Gaussian\n",
    "\n",
    "From the joint covariance:\n",
    "\n",
    "$$\n",
    "\\Sigma =\n",
    "\\begin{bmatrix}\n",
    "2 & 0.5 \\\\\n",
    "0.5 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The conditional of $y$ given $x$ is also Gaussian:\n",
    "\n",
    "---\n",
    "\n",
    "## Likelihood model\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "y \\mid x \\sim\n",
    "\\mathcal{N}\n",
    "\\left(\n",
    "\\mu_{y\\mid x},;\n",
    "\\Sigma_{y\\mid x}\n",
    "\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Mean\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mu_{y\\mid x} = \\mu_y + \\Sigma_{yx}\\Sigma_{xx}^{-1}(x - \\mu_x)\n",
    "}\n",
    "$$\n",
    "\n",
    "Plug in values:\n",
    "\n",
    "$$\n",
    "\\mu_{y\\mid x} = 0 + 0.5 \\cdot 2^{-1} (x - 5) = 0.25(x - 5)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Variance\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\Sigma_{y\\mid x} = \\Sigma_{yy} - \\Sigma_{yx}\\Sigma_{xx}^{-1}\\Sigma_{xy}\n",
    "}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_{y\\mid x} = 1 - 0.5 \\cdot 2^{-1} \\cdot 0.5 = 1 - 0.125 = 0.875\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Likelihood distribution\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(y_0 \\mid x) = \\mathcal{N}\n",
    "\\left(\n",
    "0.25(x - 5),; 0.875\n",
    "\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ What changed conceptually?\n",
    "\n",
    "| Aspect               | Conditional distribution | Likelihood     |\n",
    "| -------------------- | ------------------------ | -------------- |\n",
    "| Random variable      | $x$                      | $y$            |\n",
    "| Fixed value          | $y_0$                    | $y_0$          |\n",
    "| Variable             | $x$                      | $x$            |\n",
    "| Result               | belief over $x$          | score over $x$ |\n",
    "| Integrates to 1 over | $x$                      | ‚ùå does not     |\n",
    "\n",
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ Physical interpretation (robotics intuition)\n",
    "\n",
    "### Conditional $p(x \\mid y_0)$\n",
    "\n",
    "> \"Given the compass reading, where do I think I am?\"\n",
    "\n",
    "‚úî Used for **state estimation**\n",
    "\n",
    "---\n",
    "\n",
    "### Likelihood $p(y_0 \\mid x)$\n",
    "\n",
    "> \"If I were at position $x$, how consistent is the compass reading?\"\n",
    "\n",
    "‚úî Used for **optimization / scoring**\n",
    "\n",
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ Why SLAM uses likelihoods\n",
    "\n",
    "In SLAM we write:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(z \\mid x)\n",
    "}\n",
    "$$\n",
    "\n",
    "because:\n",
    "\n",
    "* $z$ is a fixed measurement\n",
    "* $x$ is what we optimize\n",
    "\n",
    "Taking log:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\log p(z \\mid x) = -\\frac{1}{2}(r^\\top \\Sigma^{-1} r) + \\text{const}\n",
    "}\n",
    "$$\n",
    "\n",
    "That is **least squares**.\n",
    "\n",
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Final mental rule (this resolves the confusion)\n",
    "\n",
    "> **Conditional distribution updates beliefs**\n",
    "> **Likelihood scores hypotheses**\n",
    "\n",
    "Same Gaussian.\n",
    "Same numbers.\n",
    "Different question.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69faf2b8-5497-4f06-8138-9504bc911e10",
   "metadata": {},
   "source": [
    "# Unifying Conditional Distribution, Likelihood, Kalman Filter, and Factor Graphs\n",
    "\n",
    "Excellent ‚Äî this is the **right moment** to unify everything:\n",
    "**conditional distribution**, **likelihood**, **Kalman filter**, and **factor graphs** are *the same math*, used with *different intentions*.\n",
    "\n",
    "I'll map **your exact robot example** to:\n",
    "\n",
    "1. Kalman filter **prediction vs update**\n",
    "2. A **factor graph factor**\n",
    "3. Explicitly say **what is a probability** and **what is a likelihood** in each case\n",
    "\n",
    "No new symbols unless necessary.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Your example, restated in estimation language\n",
    "\n",
    "You had a **joint Gaussian belief** over:\n",
    "\n",
    "* $x$ = robot position\n",
    "* $y$ = robot heading (compass)\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "5 \\\\\n",
    "0\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "2 & 0.5 \\\\\n",
    "0.5 & 1\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "This already encodes:\n",
    "\n",
    "* a **prior**\n",
    "* a **correlation** between state and measurement\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Mapping to Kalman filter (conceptual)\n",
    "\n",
    "Kalman filter always has **two steps**:\n",
    "\n",
    "---\n",
    "\n",
    "### üîµ Prediction step (prior)\n",
    "\n",
    "> \"Before seeing the measurement, what do I believe about the state?\"\n",
    "\n",
    "In your example, the **prior over $x$** is simply the marginal:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(x) = \\mathcal{N}(5,;2)\n",
    "}\n",
    "$$\n",
    "\n",
    "This corresponds to:\n",
    "\n",
    "* No conditioning\n",
    "* No likelihood\n",
    "* Just **probability**\n",
    "\n",
    "‚úî **Pure probability distribution**\n",
    "\n",
    "---\n",
    "\n",
    "### üî¥ Update step (conditioning)\n",
    "\n",
    "Now the robot **measures**:\n",
    "\n",
    "$$\n",
    "y = y_0\n",
    "$$\n",
    "\n",
    "Kalman asks:\n",
    "\n",
    "> \"Given this measurement, what is my updated belief about $x$?\"\n",
    "\n",
    "That is exactly what you computed:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(x \\mid y=y_0) = \\mathcal{N}\\left(5 + 0.5 y_0,; 1.75\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "‚úî This is the **Kalman update**\n",
    "‚úî This is a **conditional distribution**\n",
    "‚úî This is a **posterior**\n",
    "\n",
    "---\n",
    "\n",
    "### üîë Kalman filter form (explicit mapping)\n",
    "\n",
    "Kalman update equation:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mu^{+} = \\mu^{-} + K(y_0 - \\mu_y)\n",
    "}\n",
    "$$\n",
    "\n",
    "In your numbers:\n",
    "\n",
    "* $\\mu^{-} = 5$\n",
    "* $\\mu_y = 0$\n",
    "* $K = \\Sigma_{xy}\\Sigma_{yy}^{-1} = 0.5$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\mu^{+} = 5 + 0.5 y_0\n",
    "$$\n",
    "\n",
    "‚úî Exact match\n",
    "‚úî No new math\n",
    "‚úî Just a renamed conditional mean\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Where likelihood enters (this is crucial)\n",
    "\n",
    "Kalman filter **does not start** from the conditional.\n",
    "\n",
    "It starts from **Bayes rule**:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(x \\mid y_0) \\propto p(y_0 \\mid x) , p(x)\n",
    "}\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "* $p(x)$ ‚Üí **prior**\n",
    "* $p(y_0 \\mid x)$ ‚Üí **likelihood**\n",
    "* $p(x \\mid y_0)$ ‚Üí **posterior**\n",
    "\n",
    "---\n",
    "\n",
    "### Likelihood in *your* example\n",
    "\n",
    "From earlier, we derived:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(y_0 \\mid x) = \\mathcal{N}\\left(0.25(x - 5),; 0.875\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "This is:\n",
    "\n",
    "* **not** a belief over $x$\n",
    "* a **score**: \"If the robot were at $x$, how plausible is the measurement?\"\n",
    "\n",
    "‚úî Likelihood\n",
    "‚úî Used for **weighting hypotheses**\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Now map this to a factor graph\n",
    "\n",
    "This is where everything clicks.\n",
    "\n",
    "---\n",
    "\n",
    "### Factor graph view\n",
    "\n",
    "A **factor graph** represents:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(\\mathcal{X} \\mid \\mathcal{Z}) \\propto \\prod_f p(z_f \\mid x_f)\n",
    "}\n",
    "$$\n",
    "\n",
    "Each factor is a **likelihood**.\n",
    "\n",
    "---\n",
    "\n",
    "### Your example as a factor\n",
    "\n",
    "You would create a **measurement factor** connecting:\n",
    "\n",
    "* Variable node: $x$\n",
    "* Measurement: $y_0$\n",
    "\n",
    "The factor is:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "f(x) = p(y_0 \\mid x)\n",
    "}\n",
    "$$\n",
    "\n",
    "Nothing else.\n",
    "\n",
    "---\n",
    "\n",
    "### What optimization does\n",
    "\n",
    "Factor graph solvers do:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\arg\\max_x p(y_0 \\mid x) , p(x)\n",
    "}\n",
    "$$\n",
    "\n",
    "Taking log:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\arg\\min_x \\Bigl(\n",
    "(r^\\top \\Sigma^{-1} r)\n",
    "+\n",
    "(r_{\\text{prior}}^\\top \\Sigma_{\\text{prior}}^{-1} r_{\\text{prior}})\n",
    "\\Bigr)\n",
    "}\n",
    "$$\n",
    "\n",
    "‚úî This is MAP\n",
    "‚úî This is Kalman update\n",
    "‚úî This is least squares\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Side-by-side comparison (this is the key table)\n",
    "\n",
    "| Framework     | What it uses           | What it computes |\n",
    "| ------------- | ---------------------- | ---------------- |\n",
    "| Probability   | $p(x)$                 | belief           |\n",
    "| Likelihood    | $p(y \\mid x)$          | score            |\n",
    "| Conditional   | $p(x \\mid y)$          | updated belief   |\n",
    "| Kalman filter | likelihood + prior     | posterior        |\n",
    "| Factor graph  | product of likelihoods | MAP estimate     |\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ What changes between them?\n",
    "\n",
    "‚ùå The math\n",
    "‚ùå The Gaussian\n",
    "\n",
    "‚úÖ **Only the question**\n",
    "\n",
    "---\n",
    "\n",
    "### Same Gaussian, different roles\n",
    "\n",
    "* **Probability**: integrates to 1\n",
    "* **Likelihood**: optimized\n",
    "* **Conditional**: normalized posterior\n",
    "* **Factor**: unnormalized likelihood term\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Final unifying sentence (lock this in)\n",
    "\n",
    "> **Kalman filter marginalizes and normalizes**\n",
    "> **Factor graphs multiply likelihoods and optimize**\n",
    "> **Both are doing inference with the same Gaussian models**\n",
    "\n",
    "Once you see this, SLAM, EKF, iSAM2, and pose-graph optimization all become *the same story*.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85dc21-ed07-424f-939f-f07e53755b5b",
   "metadata": {},
   "source": [
    "Marginal and conditional distributions are concepts in probability theory and statistics that describe different aspects of the relationship between random variables. Here's an explanation of each:\n",
    "\n",
    "### Marginal Distribution\n",
    "\n",
    "The marginal distribution of a subset of a collection of random variables is the probability distribution of that subset, without reference to the values of the other variables.\n",
    "\n",
    "- **Definition**: If we have two random variables $X$ and $Y$, the marginal distribution of $X$ is the distribution of $X$ when $Y$ is not considered.\n",
    "- **Calculation**: For discrete variables, the marginal probability $P(X=x)$ is obtained by summing the joint probability over all values of $Y$:\n",
    "  $\n",
    "  P(X=x) = \\sum_y P(X=x, Y=y)\n",
    "  $\n",
    "  For continuous variables, the marginal density $f_X(x)$ is obtained by integrating the joint density over all values of $Y$:\n",
    "  $\n",
    "  f_X(x) = \\int f_{X,Y}(x,y) \\, dy\n",
    "  $\n",
    "\n",
    "### Conditional Distribution\n",
    "\n",
    "The conditional distribution of a random variable $X$ given another random variable $Y$ describes the distribution of $X$ when $Y$ is known or fixed at a certain value.\n",
    "\n",
    "- **Definition**: The conditional distribution of $X$ given $Y=y$ is the probability distribution of $X$ when $Y$ is known to be $y$.\n",
    "- **Calculation**: For discrete variables, the conditional probability $P(X=x \\mid Y=y)$ is obtained by dividing the joint probability by the marginal probability of $Y$:\n",
    "  $\n",
    "  P(X=x \\mid Y=y) = \\frac{P(X=x, Y=y)}{P(Y=y)}\n",
    "  $\n",
    "  For continuous variables, the conditional density $f_{X|Y}(x \\mid y)$ is obtained by dividing the joint density by the marginal density of $Y$:\n",
    "  $\n",
    "  f_{X|Y}(x \\mid y) = \\frac{f_{X,Y}(x,y)}{f_Y(y)}\n",
    "  $\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "- **Scope**:\n",
    "  - **Marginal Distribution**: Focuses on the probability distribution of one variable regardless of the values of other variables.\n",
    "  - **Conditional Distribution**: Focuses on the probability distribution of one variable given that the other variable(s) take specific values.\n",
    "  \n",
    "- **Independence**:\n",
    "  - If $X$ and $Y$ are independent, the conditional distribution of $X$ given $Y$ is the same as the marginal distribution of $X$, since knowing $Y$ provides no additional information about $X$.\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider a joint distribution of two discrete random variables, $X$ and $Y$:\n",
    "\n",
    "| $X$ | $Y$ | $P(X, Y)$ |\n",
    "|------|------|-------------|\n",
    "| 0    | 0    | 0.1         |\n",
    "| 0    | 1    | 0.2         |\n",
    "| 1    | 0    | 0.3         |\n",
    "| 1    | 1    | 0.4         |\n",
    "\n",
    "- **Marginal Distribution of $X$**:\n",
    "  $\n",
    "  P(X=0) = P(X=0, Y=0) + P(X=0, Y=1) = 0.1 + 0.2 = 0.3\n",
    "  $\n",
    "  $\n",
    "  P(X=1) = P(X=1, Y=0) + P(X=1, Y=1) = 0.3 + 0.4 = 0.7\n",
    "  $\n",
    "\n",
    "- **Conditional Distribution of $X$ given $Y=1$**:\n",
    "  $\n",
    "  P(X=0 \\mid Y=1) = \\frac{P(X=0, Y=1)}{P(Y=1)} = \\frac{0.2}{0.6} = \\frac{1}{3}\n",
    "  $\n",
    "  $\n",
    "  P(X=1 \\mid Y=1) = \\frac{P(X=1, Y=1)}{P(Y=1)} = \\frac{0.4}{0.6} = \\frac{2}{3}\n",
    "  $\n",
    "\n",
    "In summary, the marginal distribution provides a general view of the probability distribution of a single variable, while the conditional distribution provides insight into how one variable behaves given specific values of another variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e6af0-9718-4dd6-84ac-7a194392d31a",
   "metadata": {},
   "source": [
    "Yes ‚Äî this **discrete example maps *perfectly*** to your robot example.\n",
    "The key is to **keep the structure** and only change the *interpretation*.\n",
    "\n",
    "I‚Äôll do this in three clean steps:\n",
    "\n",
    "1. Re-interpret the **table** in robot terms\n",
    "2. Map **marginal** and **conditional** to the robot example\n",
    "3. Show where **likelihood** fits ‚Äî which is the missing piece in the table\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Re-label the discrete example in robot language\n",
    "\n",
    "Your discrete variables:\n",
    "\n",
    "* $X$ ‚Üí **robot position hypothesis**\n",
    "* $Y$ ‚Üí **sensor measurement**\n",
    "\n",
    "Let‚Äôs define them explicitly:\n",
    "\n",
    "* $X = 0$ ‚Üí robot is at position A\n",
    "\n",
    "* $X = 1$ ‚Üí robot is at position B\n",
    "\n",
    "* $Y = 0$ ‚Üí compass says ‚Äústraight‚Äù\n",
    "\n",
    "* $Y = 1$ ‚Üí compass says ‚Äúturned‚Äù\n",
    "\n",
    "Now your joint table becomes:\n",
    "\n",
    "| Robot position $X$ | Compass reading $Y$ | $P(X,Y)$ |\n",
    "| ------------------ | ------------------- | -------- |\n",
    "| A                  | straight            | 0.1      |\n",
    "| A                  | turned              | 0.2      |\n",
    "| B                  | straight            | 0.3      |\n",
    "| B                  | turned              | 0.4      |\n",
    "\n",
    "This is **exactly** analogous to your continuous joint Gaussian\n",
    "just with discrete states instead of continuous ones.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Marginal distribution = prior belief (robot)\n",
    "\n",
    "You computed:\n",
    "\n",
    "$$\n",
    "P(X=0) = 0.3\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(X=1) = 0.7\n",
    "$$\n",
    "\n",
    "### Robot interpretation\n",
    "\n",
    "> ‚ÄúBefore reading the compass, what do I believe about where the robot is?‚Äù\n",
    "\n",
    "* 30 percent chance at A\n",
    "* 70 percent chance at B\n",
    "\n",
    "This is the **prior**:\n",
    "\n",
    "‚úî Probability\n",
    "‚úî Integrates to 1\n",
    "‚úî No conditioning\n",
    "‚úî Same role as $p(x)$ in Kalman filter prediction\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Conditional distribution = posterior belief\n",
    "\n",
    "You computed:\n",
    "\n",
    "$$\n",
    "P(X=0 \\mid Y=1) = \\frac{1}{3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(X=1 \\mid Y=1) = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "### Robot interpretation\n",
    "\n",
    "> ‚ÄúGiven that the compass says ‚Äòturned‚Äô, where do I believe the robot is?‚Äù\n",
    "\n",
    "This is:\n",
    "\n",
    "‚úî Conditional probability\n",
    "‚úî Updated belief\n",
    "‚úî Discrete version of\n",
    "$\\boxed{p(x \\mid y)}$\n",
    "‚úî Exact analog of the Kalman **update step**\n",
    "\n",
    "This corresponds directly to your continuous result:\n",
    "\n",
    "> $x \\mid y=y_0 \\sim \\mathcal{N}(6,;1.75)$\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Now the missing piece: likelihood (not shown yet)\n",
    "\n",
    "Your table does **not** explicitly highlight likelihood ‚Äî but it‚Äôs already there.\n",
    "\n",
    "Likelihood is:\n",
    "\n",
    "> ‚ÄúIf the robot were at position X, how likely is the sensor reading?‚Äù\n",
    "\n",
    "That means:\n",
    "\n",
    "$$\n",
    "P(Y \\mid X)\n",
    "$$\n",
    "\n",
    "Let‚Äôs compute it from your table.\n",
    "\n",
    "---\n",
    "\n",
    "### Likelihood values\n",
    "\n",
    "For $X=0$:\n",
    "\n",
    "$$\n",
    "P(Y=1 \\mid X=0) = \\frac{0.2}{0.3}\n",
    "$$\n",
    "\n",
    "For $X=1$:\n",
    "\n",
    "$$\n",
    "P(Y=1 \\mid X=1) = \\frac{0.4}{0.7}\n",
    "$$\n",
    "\n",
    "### Robot interpretation\n",
    "\n",
    "> ‚ÄúIf the robot were at A, how plausible is the compass saying ‚Äòturned‚Äô?‚Äù\n",
    "> ‚ÄúIf the robot were at B, how plausible is that same reading?‚Äù\n",
    "\n",
    "These numbers are **scores**, not beliefs.\n",
    "\n",
    "‚úî They do **not** sum to 1 over $X$\n",
    "‚úî They are used for **weighting hypotheses**\n",
    "‚úî This is exactly what a **factor** represents\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Discrete Bayes rule (ties everything together)\n",
    "\n",
    "Your example implicitly uses:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "P(X \\mid Y)\n",
    "\\propto\n",
    "P(Y \\mid X),P(X)\n",
    "}\n",
    "$$\n",
    "\n",
    "Translate to robot terms:\n",
    "\n",
    "* $P(X)$ ‚Üí prior belief\n",
    "* $P(Y \\mid X)$ ‚Üí likelihood\n",
    "* $P(X \\mid Y)$ ‚Üí posterior belief\n",
    "\n",
    "This is **identical** to:\n",
    "\n",
    "* Kalman filter update\n",
    "* Factor graph MAP estimation\n",
    "* Your continuous Gaussian example\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Final mapping table (lock this in)\n",
    "\n",
    "| Concept     | Discrete example | Robot meaning        | Continuous analog |\n",
    "| ----------- | ---------------- | -------------------- | ----------------- |\n",
    "| Prior       | $P(X)$           | belief before sensor | $p(x)$            |\n",
    "| Likelihood  | $P(Y \\mid X)$    | sensor model         | $p(y \\mid x)$     |\n",
    "| Conditional | $P(X \\mid Y)$    | updated belief       | $p(x \\mid y)$     |\n",
    "| Factor      | $P(Y \\mid X)$    | constraint           | Gaussian factor   |\n",
    "| Update      | normalization    | Bayes rule           | Kalman update     |\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ One-sentence unifier (very important)\n",
    "\n",
    "> **Discrete tables, Kalman filters, and factor graphs differ only in representation ‚Äî not in meaning.**\n",
    "\n",
    "Same logic\n",
    "Same Bayes rule\n",
    "Same roles\n",
    "\n",
    "Only the math machinery changes.\n",
    "\n",
    "If you want, next I can:\n",
    "\n",
    "* draw the **discrete factor graph** for this table\n",
    "* show how this becomes **least squares** in the Gaussian case\n",
    "* connect this to **iSAM2 incremental updates**\n",
    "* convert your discrete example into a tiny Kalman filter\n",
    "\n",
    "Just tell me where to go next.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
